{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC7YCSyDTq3W",
        "outputId": "d683c56f-a460-42f1-87a4-79e2aa478032"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "ZYztw8L5Tq5Q",
        "outputId": "096eac68-6240-485a-bb11-8eb1de5c49f4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "0b29203fa85840d4af14f49c5565e83c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title **Install packages and dependencies**\n",
        "# @markdown Thanks to **`mamba`**, the installation takes **less than 2 mins**. \\\n",
        "# @markdown It will **restart** the kernel (session).\n",
        "\n",
        "import sys\n",
        "import time\n",
        "import contextlib\n",
        "\n",
        "with open('/content/labodock_install.log', 'a') as inpt:\n",
        "    with contextlib.redirect_stdout(inpt):\n",
        "\n",
        "        # -- Start installation --\n",
        "        start = time.time()\n",
        "        !rm -r /content/sample_data\n",
        "        !wget https://github.com/ccsb-scripps/AutoDock-Vina/releases/download/v1.2.5/vina_1.2.5_linux_x86_64 -O vina\n",
        "        !chmod u+x vina\n",
        "\n",
        "        !pip install py3Dmol==2.0.3\n",
        "        !pip install rdkit-pypi==2022.9.5\n",
        "        !pip install meeko==0.5.0\n",
        "        !pip install condacolab==0.1.7\n",
        "\n",
        "        import condacolab\n",
        "        condacolab.install_mambaforge()\n",
        "        !mamba install -c conda-forge spyrmsd=0.6.0 openbabel=3.1.1 plip=2.3.0\n",
        "        end = time.time()\n",
        "        # -- End installation --\n",
        "\n",
        "        print(f'+ Time elapsed: ' + time.strftime('%Mm %Ss', time.gmtime(end - start)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K52xS3ScTq7b"
      },
      "outputs": [],
      "source": [
        "# @title **Import all packages**\n",
        "#@markdown It will take a few minutes, please, drink a coffee and wait. ;-)\n",
        "\n",
        "%%capture\n",
        "\n",
        "!pip install biopython\n",
        "from Bio import PDB\n",
        "\n",
        "! apt-get install pymol\n",
        "from pymol import cmd\n",
        "\n",
        "\n",
        "!conda install -c conda-forge openbabel\n",
        "\n",
        "! apt-get install pymol\n",
        "from pymol import cmd\n",
        "\n",
        "!pip install biopandas\n",
        "import torch\n",
        "\n",
        "!pip install torch-geometric torch-scatter torch-sparse \\\n",
        " -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "\n",
        "!pip install rdkit\n",
        "!pip install py3Dmol\n",
        "import rdkit\n",
        "!pip install mdtraj\n",
        "!pip install openmm\n",
        "import mdtraj as md\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit.Chem import Draw\n",
        "from rdkit.Chem import rdMolTransforms\n",
        "from rdkit.Chem.Draw import rdMolDraw2D\n",
        "from rdkit.Chem import rdDepictor\n",
        "from rdkit.Chem import rdForceFieldHelpers\n",
        "from IPython.display import SVG\n",
        "import ipywidgets as widgets\n",
        "import rdkit\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "AllChem.SetPreferCoordGen(True)\n",
        "from IPython.display import Image\n",
        "import openbabel\n",
        "from openbabel import pybel\n",
        "import os\n",
        "import subprocess\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit.Chem import Draw\n",
        "from rdkit.Chem import PyMol\n",
        "import py3Dmol\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import tempfile\n",
        "\n",
        "! apt-get install plip\n",
        "import plip\n",
        "!pip install spyrmsd\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "import py3Dmol\n",
        "import plip\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive, files\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from rdkit import Chem, RDLogger\n",
        "from rdkit.Chem import rdFMCS, AllChem, Draw\n",
        "from spyrmsd import io, rmsd\n",
        "\n",
        "from plip.exchange.report import BindingSiteReport\n",
        "from plip.structure.preparation import PDBComplex\n",
        "\n",
        "print(f'+ Import completed')\n",
        "\n",
        "# Added new from PoseBusters\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from tempfile import TemporaryDirectory\n",
        "import logging\n",
        "\n",
        "from meeko import MoleculePreparation, PDBQTMolecule, RDKitMolCreate\n",
        "from pymol import cmd\n",
        "from rdkit.Chem import AddHs, MolFromMolFile, SDWriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfSFA9AbTq9D",
        "outputId": "0fe32458-4e2a-405a-ae85-6bea769a4cec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ Methods and functions successfully built\n"
          ]
        }
      ],
      "source": [
        "# @title **This part is taken from LaboDock: https://github.com/RyanZR/labodock**\n",
        "# @markdown This creates important custom functions and methods for later\n",
        "# @markdown docking and binding interaction study.\n",
        "\n",
        "%alias vina /content/vina\n",
        "\n",
        "#############################################\n",
        "# Suppress Warnings\n",
        "\n",
        "RDLogger.DisableLog('rdApp.warning')\n",
        "\n",
        "#############################################\n",
        "# Grid Box Calculation Methods\n",
        "\n",
        "class GridBox:\n",
        "\n",
        "    ranges = tuple[list[float], list[float], list[float]]\n",
        "    coords = tuple[float, float, float]\n",
        "    center_bxsize = tuple[tuple[float, float, float], tuple[float, float, float]]\n",
        "\n",
        "    def __init__(self, inpt_file: str) -> None:\n",
        "        self.inpt = open(inpt_file, 'r')\n",
        "        self.data = self.inpt.read()\n",
        "        self.cmol = Chem.MolFromPDBBlock(self.data)\n",
        "        self.conf = self.cmol.GetConformer()\n",
        "        self.ntom = self.cmol.GetNumAtoms()\n",
        "        self.inpt.close()\n",
        "\n",
        "    def update_gridbox(self, mol_block: str) -> None:\n",
        "        self.cmol = Chem.MolFromPDBBlock(mol_block)\n",
        "        self.conf = self.cmol.GetConformer()\n",
        "        self.ntom = self.cmol.GetNumAtoms()\n",
        "\n",
        "    def compute_coords(self) -> ranges:\n",
        "        x_coord = [self.conf.GetAtomPosition(c).x for c in range(self.ntom)]\n",
        "        y_coord = [self.conf.GetAtomPosition(c).y for c in range(self.ntom)]\n",
        "        z_coord = [self.conf.GetAtomPosition(c).z for c in range(self.ntom)]\n",
        "        return x_coord, y_coord, z_coord\n",
        "\n",
        "    def compute_ranges(self) -> ranges:\n",
        "        x, y, z = self.compute_coords()\n",
        "        x_range = [min(x), max(x)]\n",
        "        y_range = [min(y), max(y)]\n",
        "        z_range = [min(z), max(z)]\n",
        "        return x_range, y_range, z_range\n",
        "\n",
        "    def compute_center(self, use_range: bool = True) -> coords:\n",
        "        x, y, z = self.compute_ranges() if use_range else self.compute_coords()\n",
        "        x_center = round(np.mean(x), 3)\n",
        "        y_center = round(np.mean(y), 3)\n",
        "        z_center = round(np.mean(z), 3)\n",
        "        return x_center, y_center, z_center\n",
        "\n",
        "    def generate_res_molblock(self, residues_list: list[str]) -> str:\n",
        "        res_lines = [line for line in self.data.split('\\n')\n",
        "                     if line[22:26].lstrip() in residues_list\n",
        "                     and 'END' not in line]\n",
        "        res_block = '\\n'.join(res_lines)\n",
        "        return res_block\n",
        "\n",
        "    def labox(self, scale: float = 2.0) -> coords:\n",
        "        xr, yr, zr = self.compute_ranges()\n",
        "        center = self.compute_center()\n",
        "        bxsize = (round(abs(xr[0] - xr[1]) * scale, 3),\n",
        "                  round(abs(yr[0] - yr[1]) * scale, 3),\n",
        "                  round(abs(zr[0] - zr[1]) * scale, 3))\n",
        "        return center, bxsize\n",
        "\n",
        "    def eboxsize(self, gy_box_ratio: float = 0.23, modified: bool = False) -> center_bxsize:\n",
        "        xc, yc, zc = self.compute_coords()\n",
        "        center = self.compute_center(modified)\n",
        "        distsq = [(x-center[0])**2 + (y-center[1])**2 + (z-center[2])**2\n",
        "                  for x, y, z in zip(xc, yc, zc)]\n",
        "        bxsize = (round(np.sqrt(sum(distsq) / len(xc)) / gy_box_ratio, 3),) * 3\n",
        "        return center, bxsize\n",
        "\n",
        "    def autodock_grid(self) -> center_bxsize:\n",
        "        xr, yr, zr = self.compute_ranges()\n",
        "        center = self.compute_center()\n",
        "        bxsize = (22.5, 22.5, 22.5)\n",
        "        return center, bxsize\n",
        "\n",
        "    def defined_by_res(self, residue_number: str, scale: float = 1.25) -> center_bxsize:\n",
        "        res_list = residue_number.replace(',', ' ').split()\n",
        "        res_block = self.generate_res_molblock(res_list)\n",
        "        self.update_gridbox(res_block)\n",
        "        return self.labox(scale=scale)\n",
        "\n",
        "#############################################\n",
        "# RMSD Calculation Methods\n",
        "\n",
        "class ComputeRMSD:\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self.MCS_mol = None\n",
        "        self.MCS_png = None\n",
        "\n",
        "    def load_molecule(self, inpt_file: str, remove_Hs: bool = True) -> tuple:\n",
        "        molecule = io.loadmol(inpt_file)\n",
        "        molecule.strip() if remove_Hs else None\n",
        "        name = os.path.basename(inpt_file).split('.')[0]\n",
        "        coor = molecule.coordinates\n",
        "        anum = molecule.atomicnums\n",
        "        mtrx = molecule.adjacency_matrix\n",
        "        cmol = Chem.MolFromPDBFile(inpt_file)\n",
        "        return name, coor, anum, mtrx, cmol\n",
        "\n",
        "    def mol_to_png(self, mol: object) -> object:\n",
        "        legend = 'Maximum Common Substructure'\n",
        "        png = Draw.MolToImage(mol, legend=legend)\n",
        "        return png\n",
        "\n",
        "    def find_MCS(self, ref: tuple, lig: tuple) -> object:\n",
        "        if self.MCS_mol is None:\n",
        "            MCS_obj = rdFMCS.FindMCS([ref[4], lig[4]])\n",
        "            MCS_mol = Chem.MolFromSmarts(MCS_obj.smartsString)\n",
        "            MCS_png = self.mol_to_png(MCS_mol)\n",
        "            self.MCS_mol = MCS_mol\n",
        "            self.MCS_png = MCS_png\n",
        "        return self.MCS_mol\n",
        "\n",
        "    def hung_RMSD(self, ref: tuple, lig: tuple) -> float:\n",
        "        try:\n",
        "            hRMSD = round(rmsd.hrmsd(ref[1], lig[1], ref[2], lig[2]), 3)\n",
        "        except:\n",
        "            hRMSD = 'ERROR'\n",
        "        return hRMSD\n",
        "\n",
        "    def symm_RMSD(self, ref: tuple, lig: tuple, minimise: bool = False) -> float:\n",
        "        try:\n",
        "            sRMSD = round(rmsd.symmrmsd(ref[1], lig[1], ref[2], lig[2], ref[3], lig[3], minimize=minimise), 3)\n",
        "        except:\n",
        "            sRMSD = 'ERROR'\n",
        "        return sRMSD\n",
        "\n",
        "    def labo_RMSD(self, ref: tuple, lig: tuple) -> float:\n",
        "        mol_substr = self.find_MCS(ref, lig)\n",
        "        ref_substr = ref[4].GetSubstructMatch(mol_substr)\n",
        "        lig_substr = lig[4].GetSubstructMatch(mol_substr)\n",
        "\n",
        "        distsq = []\n",
        "        for ref_atom, lig_atom in zip(ref_substr, lig_substr):\n",
        "            ref_pos = ref[4].GetConformer().GetAtomPosition(ref_atom)\n",
        "            lig_pos = lig[4].GetConformer().GetAtomPosition(lig_atom)\n",
        "            ref_coord = np.array((ref_pos.x, ref_pos.y, ref_pos.z))\n",
        "            lig_coord = np.array((lig_pos.x, lig_pos.y, lig_pos.z))\n",
        "            coo_dist = np.linalg.norm(ref_coord - lig_coord)\n",
        "            distsq.append(coo_dist ** 2)\n",
        "\n",
        "        try:\n",
        "            lRMSD = round(np.sqrt(sum(distsq)/len(distsq)), 3)\n",
        "        except:\n",
        "            lRMSD = 'ERROR'\n",
        "        return lRMSD\n",
        "\n",
        "    def rmsd_report(self,\n",
        "                    ref: tuple,\n",
        "                    lig: tuple,\n",
        "                    lRMSD: bool = True,\n",
        "                    hRMSD: bool = True,\n",
        "                    sRMSD: bool = True\n",
        "                    ) -> dict[str: list[float]]:\n",
        "        report = {}\n",
        "        report['NAME'] = [lig[0]]\n",
        "        report['LABO_RMSD'] = [self.labo_RMSD(ref, lig)] if lRMSD else None\n",
        "        report['HUNG_RMSD'] = [self.hung_RMSD(ref, lig)] if hRMSD else None\n",
        "        report['SYMM_RMSD'] = [self.symm_RMSD(ref, lig)] if sRMSD else None\n",
        "        report = {k: v for k, v in report.items() if v is not None}\n",
        "        return report\n",
        "\n",
        "#############################################\n",
        "# AA Consntant and Bond Colour Dictionary\n",
        "\n",
        "# Kyte and Doolittle Hydropathy Scale (1982)\n",
        "AA_HB = {'ALA':  1.8, 'ARG': -4.5, 'ASN': -3.5, 'ASP': -3.5, 'CYS':  2.5,\n",
        "         'GLN': -3.5, 'GLU': -3.5, 'GLY': -0.4, 'HIS': -3.2, 'ILE':  4.5,\n",
        "         'LEU':  3.8, 'LYS': -3.9, 'MET':  1.9, 'PHE':  2.8, 'PRO': -1.6,\n",
        "         'SER': -0.8, 'THR': -0.7, 'TRP': -0.9, 'TYR': -1.3, 'VAL':  4.2}\n",
        "\n",
        "# University of Calgary PI Scale\n",
        "AA_PI = {'ALA':  6.0, 'ARG': 10.76, 'ASN': 5.41, 'ASP': 2.77, 'CYS': 5.07,\n",
        "         'GLN': 5.65, 'GLU':  3.22, 'GLY': 5.97, 'HIS': 7.59, 'ILE': 6.02,\n",
        "         'LEU': 5.98, 'LYS':  9.74, 'MET': 5.74, 'PHE': 5.48, 'PRO':  6.3,\n",
        "         'SEC': 5.68, 'SER':  5.68, 'THR':  5.6, 'TRP': 5.89, 'TYR': 5.66,\n",
        "         'VAL': 5.96}\n",
        "\n",
        "BOND_COL = {'HYDROPHOBIC': ['0x59e382', 'GREEN'],\n",
        "            'HBOND': ['0x59bee3', 'LIGHT BLUE'],\n",
        "            'WATERBRIDGE': ['0x4c4cff', 'BLUE'],\n",
        "            'SALTBRIDGE': ['0xefd033', 'YELLOW'],\n",
        "            'PISTACKING': ['0xb559e3', 'PURPLE'],\n",
        "            'PICATION': ['0xe359d8', 'VIOLET'],\n",
        "            'HALOGEN': ['0x59bee3', 'LIGHT BLUE'],\n",
        "            'METAL':['0xe35959', 'ORANGE']}\n",
        "\n",
        "#############################################\n",
        "# AA-to-Colour Converter Function\n",
        "\n",
        "def sequential_gradient(value: float,\n",
        "                        min_value: float,\n",
        "                        max_value: float,\n",
        "                        targ_colour: str = '00ff00',\n",
        "                        interpolation: float = 0.0\n",
        "                        ) -> str:\n",
        "    norm_val = (value - min_value) / (max_value - min_value)\n",
        "\n",
        "    rgb = tuple(int(targ_colour[d:d+2], 16) for d in (0, 2, 4))\n",
        "    r = int(255 - (255 - rgb[0]) * (1 - interpolation) * norm_val)\n",
        "    g = int(255 - (255 - rgb[1]) * (1 - interpolation) * norm_val)\n",
        "    b = int(255 - (255 - rgb[2]) * (1 - interpolation) * norm_val)\n",
        "\n",
        "    hex_code = f'#{r:02x}{g:02x}{b:02x}'\n",
        "    return hex_code\n",
        "\n",
        "def diverging_gradient(value: float,\n",
        "                       min_value: float,\n",
        "                       max_value: float,\n",
        "                       base_colour: str = 'ff0000',\n",
        "                       targ_colour: str = '0000ff',\n",
        "                       interpolation: float = 0.3\n",
        "                       ) -> str:\n",
        "    norm_val = (value - min_value) / (max_value - min_value)\n",
        "\n",
        "    white = (255, 255, 255)\n",
        "    rgb_A = tuple(int(base_colour[d:d+2], 16) for d in (0, 2, 4))\n",
        "    rgb_B = tuple(int(targ_colour[d:d+2], 16) for d in (0, 2, 4))\n",
        "\n",
        "    if norm_val < 0.5 - interpolation / 2:\n",
        "        factor = norm_val / (0.5 - interpolation / 2)\n",
        "        r = int(rgb_A[0] + (white[0] - rgb_A[0]) * factor)\n",
        "        g = int(rgb_A[1] + (white[1] - rgb_A[1]) * factor)\n",
        "        b = int(rgb_A[2] + (white[2] - rgb_A[2]) * factor)\n",
        "    elif norm_val > 0.5 + interpolation / 2:\n",
        "        factor = (norm_val - 0.5 - interpolation / 2) / (0.5 - interpolation / 2)\n",
        "        r = int(white[0] + (rgb_B[0] - white[0]) * factor)\n",
        "        g = int(white[1] + (rgb_B[1] - white[1]) * factor)\n",
        "        b = int(white[2] + (rgb_B[2] - white[2]) * factor)\n",
        "    else:\n",
        "        r, g, b = white\n",
        "\n",
        "    hex_code = f'#{r:02x}{g:02x}{b:02x}'\n",
        "    return hex_code\n",
        "\n",
        "def a2c_converter(aa_map: dict, grad_func: 'function') -> dict:\n",
        "    min_value = min(aa_map.values())\n",
        "    max_value = max(aa_map.values())\n",
        "    aa_dict = {aa: grad_func(value, min_value, max_value)\n",
        "               for aa, value in aa_map.items()}\n",
        "    return aa_dict\n",
        "\n",
        "#############################################\n",
        "# Built-in Styling Function\n",
        "\n",
        "def builtin_style(style: str, opacity: float = 1.0) -> dict:\n",
        "    match style:\n",
        "        case _ if any(kw in style for kw in ('Carbon', 'chain', 'ssJmol', 'ssPyMol')):\n",
        "            style_dict = {'colorscheme': style}\n",
        "        case 'hydrophobicity':\n",
        "            style_dict = {'colorscheme': {\n",
        "                'prop': 'resn', 'map': a2c_converter(AA_HB, sequential_gradient)}}\n",
        "        case 'isoelectric points':\n",
        "            style_dict = {'colorscheme': {\n",
        "                'prop': 'resn', 'map': a2c_converter(AA_PI, diverging_gradient)}}\n",
        "        case 'b factor':\n",
        "            style_dict = {'colorscheme': {\n",
        "                'prop': 'b', 'gradient': 'rwb', 'min': 90, 'max': 50}}\n",
        "        case _:\n",
        "            style_dict = {'color': style}\n",
        "\n",
        "    style_dict.update({'opacity': opacity, 'singleBonds': False})\n",
        "    return style_dict\n",
        "\n",
        "#############################################\n",
        "# Built-in Colour Scale Function\n",
        "\n",
        "def colour_scale(aa_map: dict, grad_func: 'function') -> None:\n",
        "    min_value = min(aa_map.values())\n",
        "    max_value = max(aa_map.values())\n",
        "\n",
        "    linear_values = np.linspace(min_value, max_value, 100)\n",
        "    colours = [grad_func(value, min_value, max_value)\n",
        "               for value in linear_values]\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(4.85, 0.25))\n",
        "    norm_value = plt.Normalize(min_value, max_value)\n",
        "    colour_map = plt.cm.colors.ListedColormap(colours)\n",
        "    scalar_map = plt.cm.ScalarMappable(norm_value, colour_map)\n",
        "    scalar_map.set_array([])\n",
        "\n",
        "    cscale = plt.colorbar(scalar_map, ax, orientation='horizontal')\n",
        "    cscale.set_ticks([min_value, max_value])\n",
        "\n",
        "def show_cscale(rept_info: dict, surf_info: dict) -> None:\n",
        "\n",
        "    def cs_selector() -> str:\n",
        "        if any(surf_info):\n",
        "            style = [*surf_info.values()][0]\n",
        "        elif any(rept_info):\n",
        "            style = [*rept_info.values()][0]\n",
        "        else:\n",
        "            style = None\n",
        "        return style\n",
        "\n",
        "    def cs_display(style: str):\n",
        "        if style == 'hydrophobicity':\n",
        "            label_title(style, 'Less', 'More')\n",
        "            colour_scale(AA_HB, sequential_gradient)\n",
        "        elif style == 'isoelectric points':\n",
        "            label_title(style, 'Acid', 'Base')\n",
        "            colour_scale(AA_PI, diverging_gradient)\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "    def label_title(text: str, min: str, max: str) -> None:\n",
        "        print(f'-' * 55)\n",
        "        print(f'{min}{text.upper():^47}{max}')\n",
        "        print(f'-' * 55)\n",
        "\n",
        "    cs_display(cs_selector())\n",
        "\n",
        "#############################################\n",
        "# Other Functions\n",
        "\n",
        "def extract_config(inpt_file: str) -> tuple:\n",
        "    with open(inpt_file, 'r') as inpt:\n",
        "        data = [line.split() for line in inpt.readlines()]\n",
        "    center = (float(data[0][2]), float(data[1][2]), float(data[2][2]))\n",
        "    bxsize = (float(data[4][2]), float(data[5][2]), float(data[6][2]))\n",
        "    return center, bxsize\n",
        "\n",
        "def interaction_dict(inpt_file: str, interactions: str = '', usage: str = 'view' or 'lbsp') -> dict:\n",
        "\n",
        "    usg_map = {'lbsp': 0, 'view': 1}\n",
        "\n",
        "    def filter_df(int_df: pd.DataFrame, interactions: list = []) -> pd.DataFrame:\n",
        "        int_df = int_df[int_df['BOND'].isin(interactions)] if interactions else int_df\n",
        "        return int_df\n",
        "\n",
        "    def s2f_dict(item: dict) -> dict:\n",
        "        return {key: tuple(float(val) for val in value[1:-1].split(','))\n",
        "                for key, value in item.items()}\n",
        "\n",
        "    def b2c_dict(item: dict) -> dict:\n",
        "        return {key: BOND_COL[val][usg_map[usage]] for key, val in item.items()}\n",
        "\n",
        "    intrxn = interactions.replace(',', ' ').split()\n",
        "    inter_df = pd.read_csv(inpt_file)\n",
        "    int_dict = filter_df(inter_df, intrxn).to_dict()\n",
        "    int_dict['LIGCOO'] = s2f_dict(int_dict['LIGCOO'])\n",
        "    int_dict['PROTCOO'] = s2f_dict(int_dict['PROTCOO'])\n",
        "    int_dict['COLOR'] = b2c_dict(int_dict['BOND'])\n",
        "\n",
        "    return int_dict\n",
        "\n",
        "def find_midpoint(coords: list) -> tuple[float, float, float]:\n",
        "    return tuple(round(coord, 3) for coord in np.mean(coords, axis=0))\n",
        "\n",
        "#############################################\n",
        "# LaboSpace Viewer\n",
        "\n",
        "class LaboSpace:\n",
        "\n",
        "    residue_style = {\n",
        "        'stick':\n",
        "         {'colorscheme': 'orangeCarbon', 'radius': 0.15}}\n",
        "    residue_label = {\n",
        "        'alignment': 'bottomLeft',\n",
        "        'showBackground': False,\n",
        "        'inFront': True,\n",
        "        'fontSize': 14,\n",
        "        'fontColor': '0x000000',\n",
        "        'screenOffset': {'x': 25, 'y': 25}}\n",
        "    atom_label = {\n",
        "        'alignment': 'bottomLeft',\n",
        "        'showBackground': False,\n",
        "        'inFront': True,\n",
        "        'fontSize': 14,\n",
        "        'fontColor': '0x000000',\n",
        "        'screenOffset': {'x': 10, 'y': 10}}\n",
        "\n",
        "    def __init__(self, vw: int = 500, vh: int = 500) -> None:\n",
        "        self.mview = py3Dmol.view(width=vw, height=vh)\n",
        "        self.count = -1\n",
        "        self.residues = []\n",
        "\n",
        "    def read_moldata(self, inpt_file: str) -> str:\n",
        "        inpt = open(inpt_file, 'r')\n",
        "        data = inpt.read()\n",
        "        inpt.close()\n",
        "        return data\n",
        "\n",
        "    def load_receptor(self, inpt_file: str) -> object:\n",
        "        data = self.read_moldata(inpt_file)\n",
        "        self.mview.addModel(data, 'pdb')\n",
        "        self.count += 1\n",
        "        return self\n",
        "\n",
        "    def load_ligand(self, inpt_file: str) -> object:\n",
        "        data = self.read_moldata(inpt_file)\n",
        "        self.mview.addModel(data)\n",
        "        self.count += 1\n",
        "        return self\n",
        "\n",
        "    def set_style(self,\n",
        "                  show_represent: bool = True,\n",
        "                  represent_type: str = 'cartoon',\n",
        "                  represent_style: dict = {}\n",
        "                  ) -> object:\n",
        "        if show_represent:\n",
        "            self.mview.setStyle(\n",
        "                {'model': self.count},\n",
        "                {represent_type: represent_style})\n",
        "        else:\n",
        "            self.mview.setStyle(\n",
        "                {'model': self.count},\n",
        "                {})\n",
        "        return self\n",
        "\n",
        "    def add_style(self,\n",
        "                  show_represent: bool = True,\n",
        "                  represent_style: dict = {}\n",
        "                  ) -> object:\n",
        "        if show_represent:\n",
        "            self.mview.addStyle(\n",
        "                {'model': self.count},\n",
        "                represent_style)\n",
        "        return self\n",
        "\n",
        "    def add_residues(self,\n",
        "                     show_residues: bool = True,\n",
        "                     residue_number: str = ''\n",
        "                     ) -> object:\n",
        "        if show_residues and residue_number:\n",
        "            res = residue_number.replace(',', ' ').split()\n",
        "            self.residues.extend(list(set(res)))\n",
        "            self.mview.addStyle(\n",
        "                {'and': [{'model': self.count}, {'resi': self.residues}]},\n",
        "                self.residue_style)\n",
        "            self.mview.addResLabels(\n",
        "                {'and': [{'model': self.count}, {'resi': self.residues}]},\n",
        "                self.residue_label)\n",
        "        return self\n",
        "\n",
        "    def add_surface(self,\n",
        "                    show_surface: bool = True,\n",
        "                    surface_type: str = 'SES',\n",
        "                    surface_style: dict = {}\n",
        "                    ) -> object:\n",
        "        if show_surface:\n",
        "            self.mview.addSurface(\n",
        "                surface_type,\n",
        "                surface_style,\n",
        "                {'model': self.count})\n",
        "        return self\n",
        "\n",
        "    def add_gridbox(self,\n",
        "                    show_gridbox: bool,\n",
        "                    center: list[float],\n",
        "                    bxsize: list[float]\n",
        "                    ) -> object:\n",
        "        if show_gridbox:\n",
        "            bxi, byi, bzi = center\n",
        "            bxf, byf, bzf = bxsize\n",
        "            self.mview.addBox({\n",
        "                'center': {'x': bxi, 'y': byi, 'z': bzi},\n",
        "                'dimensions': {'w': bxf, 'h': byf, 'd': bzf},\n",
        "                'color': 'skyBlue',\n",
        "                'opacity': 0.6})\n",
        "            self.mview.addLabel(\n",
        "                f'center: {bxi:>8}, {byi:>8}, {bzi:>8}',\n",
        "                {'showBackground': False,\n",
        "                 'fontSize': 14,\n",
        "                 'fontColor': '0x000000',\n",
        "                 'useScreen': True,\n",
        "                 'screenOffset': {'x': 15, 'y': 0}})\n",
        "            self.mview.addLabel(\n",
        "                f'bxsize: {bxf:>8}, {byf:>8}, {bzf:>8}',\n",
        "                {'showBackground': False,\n",
        "                 'fontSize': 14,\n",
        "                 'fontColor': '0x000000',\n",
        "                 'useScreen': True,\n",
        "                 'screenOffset': {'x': 15, 'y': -20}})\n",
        "        return self\n",
        "\n",
        "    def add_interaction(self,\n",
        "                        interaction_file: str,\n",
        "                        show_interaction: bool = True,\n",
        "                        select_interaction: list = []\n",
        "                        ) -> object:\n",
        "        if show_interaction:\n",
        "            int_dict = interaction_dict(interaction_file, select_interaction, 'lbsp')\n",
        "            dist = int_dict['DIST'].values()\n",
        "            bond = int_dict['BOND'].values()\n",
        "            resn = int_dict['RESNR'].values()\n",
        "            ligcoo = int_dict['LIGCOO'].values()\n",
        "            prtcoo = int_dict['PROTCOO'].values()\n",
        "            color = int_dict['COLOR'].values()\n",
        "\n",
        "            int_res = list(set(resn) - set(self.residues))\n",
        "            self.residues.extend(int_res)\n",
        "            self.mview.addStyle(\n",
        "                {'and': [{'model': 0}, {'resi': int_res}]},\n",
        "                self.residue_style)\n",
        "            self.mview.addResLabels(\n",
        "                {'and': [{'model': 0}, {'resi': int_res}]},\n",
        "                self.residue_label)\n",
        "\n",
        "            for dis, col, lig, prt in zip(dist, color, ligcoo, prtcoo):\n",
        "                mid = find_midpoint([lig, prt])\n",
        "                self.mview.addCylinder(\n",
        "                    {'start': {'x': lig[0], 'y': lig[1], 'z': lig[2]},\n",
        "                     'end': {'x': prt[0], 'y': prt[1], 'z': prt[2]},\n",
        "                     'radius': 0.05,\n",
        "                     'fromCap': 1,\n",
        "                     'toCap': 1,\n",
        "                     'color': col,\n",
        "                     'dashed': True})\n",
        "                self.mview.addLabel(\n",
        "                    str(dis) + ' Å',\n",
        "                    {'position': {'x': mid[0], 'y': mid[1], 'z': mid[2]},\n",
        "                     'alignment': 'bottomLeft',\n",
        "                     'inFront': False,\n",
        "                     'backgroundColor': col,\n",
        "                     'fontSize': 10,\n",
        "                     'screenOffset': {'x': 10, 'y': 10}})\n",
        "        return self\n",
        "\n",
        "    def label_atoms(self, show_label: bool = False) -> object:\n",
        "        # WARNING: Avoid applying on protein !!!\n",
        "        if show_label:\n",
        "            self.mview.addPropertyLabels(\n",
        "                'atom',\n",
        "                {'model': self.count},\n",
        "                self.atom_label)\n",
        "        return self\n",
        "\n",
        "    def view_space(self,\n",
        "                   zoom_model: int = -1,\n",
        "                   slab_view: bool = False,\n",
        "                   slab_model: int = -1,\n",
        "                   background_colour: str = '0xFFFFFF'\n",
        "                   ) -> None:\n",
        "        self.mview.setBackgroundColor(background_colour)\n",
        "        self.mview.setProjection('orthographic')\n",
        "        self.mview.zoomTo({'model': zoom_model})\n",
        "        self.mview.fitSlab({'model': slab_model}) if slab_view else None\n",
        "        self.mview.show()\n",
        "\n",
        "import py3Dmol\n",
        "\n",
        "class LaboSpaceAnother:\n",
        "    residue_style = {\n",
        "        'stick': {'colorscheme': 'orangeCarbon', 'radius': 0.15}\n",
        "    }\n",
        "    residue_label = {\n",
        "        'alignment': 'bottomLeft',\n",
        "        'showBackground': False,\n",
        "        'inFront': True,\n",
        "        'fontSize': 14,\n",
        "        'fontColor': '0x000000',\n",
        "        'screenOffset': {'x': 25, 'y': 25}\n",
        "    }\n",
        "    atom_label = {\n",
        "        'alignment': 'bottomLeft',\n",
        "        'showBackground': False,\n",
        "        'inFront': True,\n",
        "        'fontSize': 14,\n",
        "        'fontColor': '0x000000',\n",
        "        'screenOffset': {'x': 10, 'y': 10}\n",
        "    }\n",
        "\n",
        "    def __init__(self, vw: int = 500, vh: int = 500) -> None:\n",
        "        self.mview = py3Dmol.view(width=vw, height=vh)\n",
        "        self.count = -1\n",
        "        self.residues = []\n",
        "\n",
        "    def read_moldata(self, inpt_file: str) -> str:\n",
        "        with open(inpt_file, 'r') as f:\n",
        "            data = f.read()\n",
        "        return data\n",
        "\n",
        "    def load_receptor(self, inpt_file: str) -> object:\n",
        "        data = self.read_moldata(inpt_file)\n",
        "        self.mview.addModel(data, 'pdb')\n",
        "        self.count += 1\n",
        "        return self\n",
        "\n",
        "    def load_ligand(self, inpt_file: str) -> object:\n",
        "        data = self.read_moldata(inpt_file)\n",
        "        self.mview.addModel(data)\n",
        "        self.count += 1\n",
        "        return self\n",
        "\n",
        "    def load_pocket(self, pocket_file: str) -> object:\n",
        "        data = self.read_moldata(pocket_file)\n",
        "        self.mview.addModel(data)\n",
        "        self.count += 1\n",
        "        return self\n",
        "\n",
        "    def set_style(self,\n",
        "                  show_represent: bool = True,\n",
        "                  represent_type: str = 'cartoon',\n",
        "                  represent_style: dict = {}\n",
        "                  ) -> object:\n",
        "        if show_represent:\n",
        "            self.mview.setStyle(\n",
        "                {'model': self.count},\n",
        "                {represent_type: represent_style}\n",
        "            )\n",
        "        else:\n",
        "            self.mview.setStyle(\n",
        "                {'model': self.count},\n",
        "                {}\n",
        "            )\n",
        "        return self\n",
        "\n",
        "    def add_style(self,\n",
        "                  show_represent: bool = True,\n",
        "                  represent_style: dict = {}\n",
        "                  ) -> object:\n",
        "        if show_represent:\n",
        "            self.mview.addStyle(\n",
        "                {'model': self.count},\n",
        "                represent_style\n",
        "            )\n",
        "        return self\n",
        "\n",
        "    def add_residues(self,\n",
        "                     show_residues: bool = True,\n",
        "                     residue_number: str = ''\n",
        "                     ) -> object:\n",
        "        if show_residues and residue_number:\n",
        "            res = residue_number.replace(',', ' ').split()\n",
        "            self.residues.extend(list(set(res)))\n",
        "            self.mview.addStyle(\n",
        "                {'and': [{'model': self.count}, {'resi': self.residues}]},\n",
        "                self.residue_style\n",
        "            )\n",
        "            self.mview.addResLabels(\n",
        "                {'and': [{'model': self.count}, {'resi': self.residues}]},\n",
        "                self.residue_label\n",
        "            )\n",
        "        return self\n",
        "\n",
        "    def add_surface(self,\n",
        "                    show_surface: bool = True,\n",
        "                    surface_type: str = 'SES',\n",
        "                    surface_style: dict = {}\n",
        "                    ) -> object:\n",
        "        if show_surface:\n",
        "            self.mview.addSurface(\n",
        "                surface_type,\n",
        "                surface_style,\n",
        "                {'model': self.count}\n",
        "            )\n",
        "        return self\n",
        "\n",
        "    def add_gridbox(self,\n",
        "                    show_gridbox: bool,\n",
        "                    center: list[float],\n",
        "                    bxsize: list[float]\n",
        "                    ) -> object:\n",
        "        if show_gridbox:\n",
        "            bxi, byi, bzi = center\n",
        "            bxf, byf, bzf = bxsize\n",
        "            self.mview.addBox({\n",
        "                'center': {'x': bxi, 'y': byi, 'z': bzi},\n",
        "                'dimensions': {'w': bxf, 'h': byf, 'd': bzf},\n",
        "                'color': 'skyBlue',\n",
        "                'opacity': 0.6\n",
        "            })\n",
        "            self.mview.addLabel(\n",
        "                f'center: {bxi:>8}, {byi:>8}, {bzi:>8}',\n",
        "                {'showBackground': False,\n",
        "                 'fontSize': 14,\n",
        "                 'fontColor': '0x000000',\n",
        "                 'useScreen': True,\n",
        "                 'screenOffset': {'x': 15, 'y': 0}}\n",
        "            )\n",
        "            self.mview.addLabel(\n",
        "                f'bxsize: {bxf:>8}, {byf:>8}, {bzf:>8}',\n",
        "                {'showBackground': False,\n",
        "                 'fontSize': 14,\n",
        "                 'fontColor': '0x000000',\n",
        "                 'useScreen': True,\n",
        "                 'screenOffset': {'x': 15, 'y': -20}}\n",
        "            )\n",
        "        return self\n",
        "\n",
        "    def add_interaction(self,\n",
        "                        interaction_file: str,\n",
        "                        show_interaction: bool = True,\n",
        "                        select_interaction: list = []\n",
        "                        ) -> object:\n",
        "        if show_interaction:\n",
        "            # Implementation for interaction visualization goes here\n",
        "            pass\n",
        "        return self\n",
        "\n",
        "    def label_atoms(self, show_label: bool = False) -> object:\n",
        "        if show_label:\n",
        "            self.mview.addPropertyLabels(\n",
        "                'atom',\n",
        "                {'model': self.count},\n",
        "                self.atom_label\n",
        "            )\n",
        "        return self\n",
        "\n",
        "    def view_space(self,\n",
        "                   zoom_model: int = -1,\n",
        "                   slab_view: bool = False,\n",
        "                   slab_model: int = -1,\n",
        "                   background_colour: str = '0xFFFFFF') -> None:\n",
        "        self.mview.setBackgroundColor(background_colour)\n",
        "        self.mview.setProjection('orthographic')\n",
        "        self.mview.zoomTo({'model': zoom_model})\n",
        "        self.mview.fitSlab({'model': slab_model}) if slab_view else None\n",
        "        self.mview.show()\n",
        "\n",
        "print(f'+ Methods and functions successfully built')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT71S-Qn-Qvp",
        "outputId": "9adbf8dd-3921-4114-f3c5-a43720faa5dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "308"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "subfolder_list_file = '/content/gdrive/MyDrive/Another_Attempt_Docking/posebusters_pdb_ccd_ids.txt'\n",
        "with open(subfolder_list_file, 'r') as file:\n",
        "    subfolder_names_to_scan = [line.strip() for line in file]\n",
        "len(subfolder_names_to_scan)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Generate config files**\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from Bio.PDB import PDBParser\n",
        "\n",
        "base_dir = '/content/gdrive/MyDrive/Docking_benchmarks/PB_new_run/posebusters_benchmark_set_SET38'\n",
        "\n",
        "subfolder_list_file = subfolder_list_file\n",
        "\n",
        "# thresholds\n",
        "minimal_thresholds = [2, 5, 10, 15]\n",
        "majority_threshold = [2, 5]\n",
        "\n",
        "def process_pocket(pocket_path, pocket_name, thresholds, output_dir):\n",
        "    try:\n",
        "        print(f\"Processing pocket file: {pocket_path}\")\n",
        "        parser = PDBParser(QUIET=True)\n",
        "        structure = parser.get_structure(pocket_name, pocket_path)\n",
        "\n",
        "        atoms = [atom for atom in structure.get_atoms()]\n",
        "        coords = [atom.coord for atom in atoms]\n",
        "        coords = np.array(coords)\n",
        "\n",
        "        max_coords = np.max(coords, axis=0)\n",
        "        min_coords = np.min(coords, axis=0)\n",
        "\n",
        "        center = (max_coords + min_coords) / 2\n",
        "\n",
        "        for threshold in thresholds:\n",
        "            DELTAx = (max_coords[0] - min_coords[0]) + 2 * threshold\n",
        "            DELTAy = (max_coords[1] - min_coords[1]) + 2 * threshold\n",
        "            DELTAz = (max_coords[2] - min_coords[2]) + 2 * threshold\n",
        "\n",
        "            config_content = f\"\"\"\\\n",
        "center_x = {center[0]}\n",
        "center_y = {center[1]}\n",
        "center_z = {center[2]}\n",
        "\n",
        "size_x = {DELTAx}\n",
        "size_y = {DELTAy}\n",
        "size_z = {DELTAz}\n",
        "\"\"\"\n",
        "            config_filename = f\"{pocket_name}_config_{threshold}.txt\"\n",
        "            config_file_path = os.path.join(output_dir, config_filename)\n",
        "\n",
        "            with open(config_file_path, 'w') as config_file:\n",
        "                config_file.write(config_content)\n",
        "\n",
        "            result_dir_name = f\"{pocket_name}_results_{threshold}\"\n",
        "            result_dir_path = os.path.join(output_dir, result_dir_name)\n",
        "            os.makedirs(result_dir_path, exist_ok=True)\n",
        "\n",
        "            print(f\"Generated config file: {config_file_path}\")\n",
        "            print(f\"Created results directory: {result_dir_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing pocket file {pocket_path}: {e}\")\n",
        "\n",
        "with open(subfolder_list_file, 'r') as f:\n",
        "    subfolder_list = f.read().splitlines()\n",
        "\n",
        "for subfolder in subfolder_list:\n",
        "    subfolder_path = os.path.join(base_dir, subfolder)\n",
        "\n",
        "    if not os.path.exists(subfolder_path):\n",
        "        print(f\"Subfolder {subfolder} does not exist. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing subfolder: {subfolder_path}\")\n",
        "\n",
        "    try:\n",
        "        minimal_pocket_files = [file for file in os.listdir(subfolder_path) if \"pocket_thr05_Minimal\" in file]\n",
        "\n",
        "        for pocket_file in minimal_pocket_files:\n",
        "            pocket_path = os.path.join(subfolder_path, pocket_file)\n",
        "            pocket_name = os.path.splitext(pocket_file)[0]\n",
        "            process_pocket(pocket_path, pocket_name, minimal_thresholds, subfolder_path)\n",
        "\n",
        "        majority_pocket_files = [file for file in os.listdir(subfolder_path) if \"pocket_thr05_Majority\" in file]\n",
        "\n",
        "        for pocket_file in majority_pocket_files:\n",
        "            pocket_path = os.path.join(subfolder_path, pocket_file)\n",
        "            pocket_name = os.path.splitext(pocket_file)[0]\n",
        "            process_pocket(pocket_path, pocket_name, majority_threshold, subfolder_path)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing subfolder {subfolder_path}: {e}\")\n",
        "\n",
        "print(\"Processing completed.\")"
      ],
      "metadata": {
        "id": "N0rC_NWO7bWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ugSLJEiMkS0"
      },
      "outputs": [],
      "source": [
        "#@title **START ADAPTIVE DOCKING!!!**\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "from meeko import PDBQTMolecule, RDKitMolCreate\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import SDWriter\n",
        "\n",
        "base_dir = '/content/gdrive/MyDrive/Docking_benchmarks/PB_new_run/posebusters_benchmark_set_SET38'\n",
        "\n",
        "subfolder_list_file = '/content/gdrive/MyDrive/Another_Attempt_Docking/posebusters_pdb_ccd_ids.txt'\n",
        "\n",
        "with open(subfolder_list_file, 'r') as file:\n",
        "    subfolder_names_to_scan = [line.strip() for line in file]\n",
        "\n",
        "print(\"Processing subfolders:\", len(subfolder_names_to_scan))\n",
        "\n",
        "cpu_cores = os.cpu_count()\n",
        "\n",
        "Exhaustiveness = '32'\n",
        "num_modes = 40\n",
        "\n",
        "def extract_vina_scores(log_file, output_csv):\n",
        "    with open(log_file, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    scores = []\n",
        "    start_collecting = False\n",
        "    for line in lines:\n",
        "        if start_collecting:\n",
        "            parts = line.split()\n",
        "            if len(parts) == 4 and parts[0].isdigit():\n",
        "                scores.append({\n",
        "                    \"NAME\": f\"{os.path.basename(log_file).split('_')[0]}_{parts[0]}\",\n",
        "                    \"DOCK_SC\": parts[1],\n",
        "                    \"RMSD_LB\": parts[2],\n",
        "                    \"RMSD_UB\": parts[3]\n",
        "                })\n",
        "\n",
        "        if \"mode |   affinity | dist from best mode\" in line:\n",
        "            start_collecting = True\n",
        "\n",
        "    df = pd.DataFrame(scores)\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f'+ {output_csv} > DOCKING folder')\n",
        "\n",
        "for subfolder in subfolder_names_to_scan:\n",
        "    subfolder_path = os.path.join(base_dir, subfolder)\n",
        "    if os.path.isdir(subfolder_path):\n",
        "        for pocket_file in os.listdir(subfolder_path):\n",
        "            if (\"pocket_thr05_Minimal\" in pocket_file or \"pocket_thr05_Majority\" in pocket_file) and pocket_file.endswith(\".pdb\"):\n",
        "                pocket_name = os.path.splitext(pocket_file)[0]\n",
        "                for threshold in [2, 5, 10, 15]:\n",
        "                    if \"pocket_thr05_Majority\" in pocket_file and threshold not in [2, 5]:\n",
        "                        continue\n",
        "\n",
        "                    protein_file = os.path.join(subfolder_path, f\"{os.path.basename(subfolder)}_protein_reduce_rm_bad_input.pdbqt\")\n",
        "                    ligand_file = os.path.join(subfolder_path, f\"{os.path.basename(subfolder)}_ligand_start_conf_prepared.pdbqt\")\n",
        "                    config_file = os.path.join(subfolder_path, f\"{pocket_name}_config_{threshold}.txt\")\n",
        "                    docking_folder = os.path.join(subfolder_path, f\"{pocket_name}_results_{threshold}\")\n",
        "\n",
        "                    if not os.path.exists(protein_file) or not os.path.exists(ligand_file):\n",
        "                        print(f\"Protein or ligand file missing for {subfolder}\")\n",
        "                        continue\n",
        "\n",
        "                    ID = f\"{os.path.basename(subfolder)}_{pocket_name}_{threshold}\"\n",
        "                    oupt_log = f\"{ID}_output.log\"\n",
        "                    oupt_pdbqt = f\"{ID}_output.pdbqt\"\n",
        "                    oupt_log_dFFile = os.path.join(docking_folder, oupt_log)\n",
        "                    oupt_pdbqt_dFFile = os.path.join(docking_folder, oupt_pdbqt)\n",
        "\n",
        "                    print(f\"Starting docking for {ID}...\")\n",
        "\n",
        "                    # -- Start docking --\n",
        "                    start = time.time()\n",
        "                    %vina --receptor {protein_file} --ligand {ligand_file} \\\n",
        "                    --out {oupt_pdbqt_dFFile} --config {config_file} --cpu {cpu_cores} \\\n",
        "                    --exhaustiveness {Exhaustiveness} --num_modes {num_modes} --verbosity 2 | tee {oupt_log_dFFile}\n",
        "                    end = time.time()\n",
        "                    # -- End docking --\n",
        "\n",
        "                    print(f\"Docking completed for {ID} in {end - start:.2f} seconds.\")\n",
        "\n",
        "                    with open(oupt_pdbqt_dFFile, 'r') as oupt:\n",
        "                        output_pdbqt = oupt.read()\n",
        "\n",
        "                    pdbqt_mol = PDBQTMolecule(output_pdbqt)\n",
        "                    rdkit_mol = RDKitMolCreate.from_pdbqt_mol(pdbqt_mol)[0]\n",
        "\n",
        "                    for conf_id in range(rdkit_mol.GetNumConformers()):\n",
        "                        LIG_dash_sdf = f\"{ID}_pose_{conf_id + 1}.sdf\"\n",
        "                        LIG_dash_sdf_dFFile = os.path.join(docking_folder, LIG_dash_sdf)\n",
        "                        writer = SDWriter(str(LIG_dash_sdf_dFFile))\n",
        "                        writer.write(rdkit_mol, confId=conf_id)\n",
        "                        writer.close()\n",
        "\n",
        "                    extract_vina_scores(oupt_log_dFFile, os.path.join(docking_folder, f\"{ID}_dockrpt.csv\"))\n",
        "    else:\n",
        "        print(f\"Subfolder {subfolder} does not exist. Skipping.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P8G6DJDX7bZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Example for 1 protein-ligand**\n",
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "base_dir = '/content/gdrive/MyDrive/Docking_benchmarks/posebusters_fourth_run/posebusters_benchmark_set/6M73_FNR'\n",
        "\n",
        "docking_scores = {}\n",
        "\n",
        "def list_files_in_directory(directory, extension):\n",
        "    file_paths = []\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(extension):\n",
        "                file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "csv_files = list_files_in_directory(base_dir, \"_dockrpt.csv\")\n",
        "\n",
        "print(f\"All CSV files found in {base_dir} and subdirectories:\")\n",
        "for file in csv_files:\n",
        "    print(file)\n",
        "\n",
        "for file_path in csv_files:\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "        print(f\"CSV Columns in {file_path}: {df.columns}\")\n",
        "        if 'DOCK_SC' in df.columns:\n",
        "            scores = df['DOCK_SC'].astype(float).tolist()\n",
        "            for score in scores:\n",
        "                docking_scores[score] = file_path\n",
        "            print(f\"Found docking scores in {file_path}: {scores}\")\n",
        "        else:\n",
        "            print(f\"DOCK_SC column not found in {file_path}\")\n",
        "    except pd.errors.EmptyDataError:\n",
        "        print(f\"CSV file is empty: {file_path}\")\n",
        "    except pd.errors.ParserError:\n",
        "        print(f\"CSV file is malformed: {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading CSV file {file_path}: {e}\")\n",
        "\n",
        "print(f\"Total number of docking scores found: {len(docking_scores)}\")\n",
        "print(\"Docking scores:\", list(docking_scores.keys()))\n",
        "\n",
        "# Find the most energetically favorable binding pose (i.e., the pose with the lowest docking score)\n",
        "if docking_scores:\n",
        "    most_favorable_score = min(docking_scores.keys())\n",
        "    most_favorable_file = docking_scores[most_favorable_score]\n",
        "    print(f\"Most energetically favorable docking score: {most_favorable_score}\")\n",
        "    print(f\"File containing the most energetically favorable pose: {most_favorable_file}\")\n",
        "    # Extract the folder path\n",
        "    most_favorable_folder = os.path.dirname(most_favorable_file)\n",
        "    print(f\"Folder containing the most energetically favorable pose: {most_favorable_folder}\")\n",
        "\n",
        "    # Search for the file ending in '_pose_1.sdf' within the most favorable folder\n",
        "    leading_pose_file = None\n",
        "    for root, dirs, files in os.walk(most_favorable_folder):\n",
        "        for file in files:\n",
        "            if file.endswith(\"_pose_1.sdf\"):\n",
        "                leading_pose_file = os.path.join(root, file)\n",
        "                break\n",
        "        if leading_pose_file:\n",
        "            break\n",
        "\n",
        "    if leading_pose_file:\n",
        "        print(f\"Leading binding pose file found: {leading_pose_file}\")\n",
        "        # Extract the protein name from the base directory\n",
        "        protein_name = os.path.basename(base_dir)\n",
        "        new_file_name = f\"{protein_name}_predicted_pose.sdf\"\n",
        "        new_file_path = os.path.join(base_dir, new_file_name)\n",
        "\n",
        "        # Copy the leading binding pose file to the base directory with the new name\n",
        "        shutil.copy(leading_pose_file, new_file_path)\n",
        "        print(f\"Leading binding pose file copied to: {new_file_path}\")\n",
        "    else:\n",
        "        print(\"No leading binding pose file found ending with '_pose_1.sdf'.\")\n",
        "else:\n",
        "    print(\"No docking scores found.\")\n"
      ],
      "metadata": {
        "id": "ZI92HqzI7bdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HVoO7pjgU4_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Process the output of adaptive docking choosing the most enegetically favorable pose**\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "# Base directory containing all subfolders with docking results\n",
        "base_dir = '/content/gdrive/MyDrive/Docking_benchmarks/posebusters_adaptive'\n",
        "\n",
        "# Path to the file containing the list of subfolder names\n",
        "subfolder_list_file = '/content/gdrive/MyDrive/Another_Attempt_Docking/posebusters_pdb_ccd_ids.txt'\n",
        "\n",
        "# Read the list of subfolder names\n",
        "with open(subfolder_list_file, 'r') as f:\n",
        "    subfolder_list = f.read().splitlines()\n",
        "\n",
        "# Function to list all files in a directory recursively\n",
        "def list_files_in_directory(directory, extension):\n",
        "    file_paths = []\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith(extension):\n",
        "                file_paths.append(os.path.join(root, file))\n",
        "    return file_paths\n",
        "\n",
        "# Process each subfolder in the base directory that is in the subfolder list\n",
        "for subfolder_name in os.listdir(base_dir):\n",
        "    if subfolder_name in subfolder_list:\n",
        "        subfolder_path = os.path.join(base_dir, subfolder_name)\n",
        "        if os.path.isdir(subfolder_path):\n",
        "            # Initialize a dictionary to store all docking scores and their corresponding file paths\n",
        "            docking_scores = {}\n",
        "\n",
        "            csv_files = list_files_in_directory(subfolder_path, \"_dockrpt.csv\")\n",
        "\n",
        "            print(f\"\\nAll CSV files found in {subfolder_path} and subdirectories:\")\n",
        "            for file in csv_files:\n",
        "                print(file)\n",
        "\n",
        "            for file_path in csv_files:\n",
        "                try:\n",
        "                    df = pd.read_csv(file_path)\n",
        "                    print(f\"CSV Columns in {file_path}: {df.columns}\")\n",
        "                    if 'DOCK_SC' in df.columns:\n",
        "                        scores = df['DOCK_SC'].astype(float).tolist()\n",
        "                        for score in scores:\n",
        "                            docking_scores[score] = file_path\n",
        "                        print(f\"Found docking scores in {file_path}: {scores}\")\n",
        "                    else:\n",
        "                        print(f\"DOCK_SC column not found in {file_path}\")\n",
        "                except pd.errors.EmptyDataError:\n",
        "                    print(f\"CSV file is empty: {file_path}\")\n",
        "                except pd.errors.ParserError:\n",
        "                    print(f\"CSV file is malformed: {file_path}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error reading CSV file {file_path}: {e}\")\n",
        "\n",
        "            # Print all the docking scores found\n",
        "            print(f\"\\nTotal number of docking scores found in {subfolder_name}: {len(docking_scores)}\")\n",
        "            print(\"Docking scores:\", list(docking_scores.keys()))\n",
        "\n",
        "            # Find the most energetically favorable binding pose (i.e., the pose with the lowest docking score)\n",
        "            if docking_scores:\n",
        "                most_favorable_score = min(docking_scores.keys())\n",
        "                most_favorable_file = docking_scores[most_favorable_score]\n",
        "                print(f\"Most energetically favorable docking score: {most_favorable_score}\")\n",
        "                print(f\"File containing the most energetically favorable pose: {most_favorable_file}\")\n",
        "                # Extract the folder path\n",
        "                most_favorable_folder = os.path.dirname(most_favorable_file)\n",
        "                print(f\"Folder containing the most energetically favorable pose: {most_favorable_folder}\")\n",
        "\n",
        "                # Search for the file ending in '_pose_1.sdf' within the most favorable folder\n",
        "                leading_pose_file = None\n",
        "                for root, dirs, files in os.walk(most_favorable_folder):\n",
        "                    for file in files:\n",
        "                        if file.endswith(\"_pose_1.sdf\"):\n",
        "                            leading_pose_file = os.path.join(root, file)\n",
        "                            break\n",
        "                    if leading_pose_file:\n",
        "                        break\n",
        "\n",
        "                if leading_pose_file:\n",
        "                    print(f\"Leading binding pose file found: {leading_pose_file}\")\n",
        "                    protein_name = subfolder_name\n",
        "                    new_file_name = f\"{protein_name}_predicted_pose.sdf\"\n",
        "                    new_file_path = os.path.join(subfolder_path, new_file_name)\n",
        "\n",
        "                    shutil.copy(leading_pose_file, new_file_path)\n",
        "                    print(f\"Leading binding pose file copied to: {new_file_path}\")\n",
        "                else:\n",
        "                    print(\"No leading binding pose file found ending with '_pose_1.sdf'.\")\n",
        "            else:\n",
        "                print(\"No docking scores found in {subfolder_name}.\")\n",
        "\n",
        "print(\"Processing completed for all selected subfolders.\")\n"
      ],
      "metadata": {
        "id": "cULU87_uU5Gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UmhRlMfcU5Jj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}