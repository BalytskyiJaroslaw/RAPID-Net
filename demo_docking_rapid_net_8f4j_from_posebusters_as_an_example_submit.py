# -*- coding: utf-8 -*-
"""Demo_docking_RAPID_Net_8F4J_from_PoseBusters_as_an_example_submit.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hmHaU2tXp109bAyZ82B4mRYMrQBsCykm

<img src="https://raw.githubusercontent.com/BalytskyiJaroslaw/RAPID-Net/main/RAPID_combine.png" height="260" align="top" style="height:260px">

# **Targeted üéØ Docking by RAPID-Net**  

RAPID-Net is a deep-learning model that **_<u>catches</u>_ binding pockets** in protein structures, and **automatically generates docking search grids**

### **üîπ What This Notebook Covers**  
‚úÖ **Pocket prediction** using RAPID-Net  

‚úÖ **Automated search grid generation** for AutoDock Vina.  

‚úÖ **Docking** with AutoDock Vina using the generated grids.

‚úÖ **Processing the output** from AutoDock Vina

‚úÖ **Identification of distant binding sites for several proteins of therapeutic importance**

Improving molecular docking and drug design üöÄ
"""

# @title **üîß Set Up the Colab Environment** { display-mode: "form" }

# @markdown **Press the ‚ñ∂Ô∏è Play button to set up the environment.**
# @markdown - ‚ö†Ô∏è After execution, the runtime will be restarted.
# @markdown - After restarting the session, press ‚ñ∂Ô∏è **Play** again.
# @markdown - This will install **Conda** and required dependencies.

import os
import io

print("\nüîß Installing Conda environment in Colab... Please wait.")

# --- Suppress installation output ---
from IPython.utils import io

with io.capture_output() as captured:
    !pip install -q condacolab
    import condacolab
    condacolab.install()

print("\n‚úÖ Conda installation verified!")
condacolab.check()
print("\nüîß Installing OpenBabel from Conda-Forge... Please wait.")
with io.capture_output() as captured:
    !conda install -q -y -c conda-forge openbabel

print("\n‚úÖ Final Conda check...")
condacolab.check()

import openbabel
from openbabel import pybel

print("\nüéâ Setup Complete! ü¶Å You can now use Conda & OpenBabel in Colab. üöÄ")

# Commented out IPython magic to ensure Python compatibility.
# @title **ü¶Å Initialize the RAPID-Net Model** { display-mode: "form" }
# @markdown RAPID-Net model parameters for pocket detection.
# @markdown - The **voxel classification threshold** is the minimum density `threshold_input` for a voxel to be considered part of a pocket. *(Default: 0.5)*
# @markdown - In other words, the $2\,√Ö\times 2\,√Ö \times 2\,√Ö$ voxel is added to the pocket if probability > 50% by default.
# @markdown - **"Minority-reported"** pockets include voxels detected by at least `min_vote_minimal` models from an ensemble of 5 models. *(Default: 1)*
# @markdown - **"Majority-voted"** pockets include voxels detected by at least `min_vote_majority` models from an ensemble. *(Default: 3)*
import warnings
warnings.filterwarnings('ignore')

threshold_input = 0.5  # @param {type:"number"}
min_vote_minimal = 1   # @param {type:"integer"}
min_vote_majority = 3   # @param {type:"integer"}

import contextlib

print("üîÑ Installing dependencies (py3Dmol, Biopython, RDKit, Meeko, PyMOL)...")
!pip install meeko
!pip install py3Dmol biopython rdkit==2024.09.1
!conda install -c conda-forge pymol-open-source -y

print("‚úÖ Dependencies installed!")


import tensorflow as tf
from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate, BatchNormalization, Activation, add, SpatialDropout3D, GlobalAveragePooling3D, Reshape, Dense, multiply, LayerNormalization
from tensorflow.keras.models import Model
from tensorflow.keras.regularizers import l2
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import backend as K


import os
from Bio.PDB import PDBParser
import numpy as np


def identity_block(input_tensor, filters, stage, block):
    filters1, filters2, filters3 = filters
    bn_axis = -1

    conv_name_base = 'res' + str(stage) + block + '_branch'
    bn_name_base = 'bn' + str(stage) + block + '_branch'

    x = Conv3D(filters1, (1, 1, 1), kernel_initializer='he_normal', name=conv_name_base + '2a')(input_tensor)
    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)
    x = Activation('relu')(x)

    x = Conv3D(filters2, (3, 3, 3), padding='same', kernel_initializer='he_normal', name=conv_name_base + '2b')(x)
    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)
    x = Activation('relu')(x)

    x = Conv3D(filters3, (1, 1, 1), kernel_initializer='he_normal', name=conv_name_base + '2c')(x)
    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)

    x = add([x, input_tensor])
    x = Activation('relu')(x)
    return x

def conv_block(input_tensor, filters, stage, block, strides=(2, 2, 2)):
    filters1, filters2, filters3 = filters
    bn_axis = -1

    conv_name_base = 'res' + str(stage) + block + '_branch'
    bn_name_base = 'bn' + str(stage) + block + '_branch'

    x = Conv3D(filters1, (1, 1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base + '2a')(input_tensor)
    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)
    x = Activation('relu')(x)

    x = Conv3D(filters2, (3, 3, 3), padding='same', kernel_initializer='he_normal', name=conv_name_base + '2b')(x)
    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)
    x = Activation('relu')(x)

    x = Conv3D(filters3, (1, 1, 1), kernel_initializer='he_normal', name=conv_name_base + '2c')(x)
    x = BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)

    shortcut = Conv3D(filters3, (1, 1, 1), strides=strides, kernel_initializer='he_normal', name=conv_name_base + '1')(input_tensor)
    shortcut = BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)

    x = add([x, shortcut])
    x = Activation('relu')(x)
    return x

def se_block(input_tensor, ratio=16):
    channel_axis = -1
    filters = input_tensor.shape[channel_axis]

    se = GlobalAveragePooling3D()(input_tensor)
    se = Reshape((1, 1, 1, filters))(se)
    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)
    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)
    x = multiply([input_tensor, se])
    return x

def RAPID_Net(input_shape=(36, 36, 36, 18), filters=18, dropout_rate=0.5, l2_lambda=1e-3):
    params = {'kernel_size': 3, 'activation': 'relu', 'padding': 'same', 'kernel_regularizer': l2(l2_lambda)}

    inputs = Input(shape=input_shape, name='input')

    x = conv_block(inputs, [filters, filters, filters], stage=2, block='a', strides=(1, 1, 1))
    x1 = identity_block(x, [filters, filters, filters], stage=2, block='b')

    pool1 = MaxPooling3D(pool_size=(2, 2, 2))(x1)

    x = conv_block(pool1, [filters*2, filters*2, filters*2], stage=4, block='a', strides=(1, 1, 1))
    x2 = identity_block(x, [filters*2, filters*2, filters*2], stage=4, block='b')

    pool2 = MaxPooling3D(pool_size=(2, 2, 2))(x2)

    x = conv_block(pool2, [filters*4, filters*4, filters*4], stage=5, block='a', strides=(1, 1, 1))
    x3 = identity_block(x, [filters*4, filters*4, filters*4], stage=5, block='b')

    pool3 = MaxPooling3D(pool_size=(3, 3, 3))(x3)

    x = conv_block(pool3, [filters*8, filters*8, filters*8], stage=6, block='a', strides=(1, 1, 1))
    x4 = identity_block(x, [filters*8, filters*8, filters*8], stage=6, block='b')

    pool4 = MaxPooling3D(pool_size=(3, 3, 3))(x4)

    x = conv_block(pool4, [filters*16, filters*16, filters*16], stage=7, block='a', strides=(1, 1, 1))
    x = identity_block(x, [filters*16, filters*16, filters*16], stage=7, block='b')

    x = se_block(x)

    up6 = concatenate([UpSampling3D(size=(3, 3, 3))(x), x4], axis=-1)
    conv6 = Conv3D(filters=filters*8, **params)(up6)
    conv6 = BatchNormalization()(conv6)
    conv6 = Activation('relu')(conv6)

    conv6 = Conv3D(filters=filters*8, **params)(conv6)
    conv6 = BatchNormalization()(conv6)
    conv6 = Activation('relu')(conv6)

    up7 = concatenate([UpSampling3D(size=(3, 3, 3))(conv6), x3], axis=-1)
    conv7 = Conv3D(filters=filters*4, **params)(up7)
    conv7 = BatchNormalization()(conv7)
    conv7 = Activation('relu')(conv7)

    conv7 = Conv3D(filters=filters*4, **params)(conv7)
    conv7 = BatchNormalization()(conv7)
    conv7 = Activation('relu')(conv7)

    up8 = concatenate([UpSampling3D(size=(2, 2, 2))(conv7), x2], axis=-1)
    conv8 = Conv3D(filters=filters*2, **params)(up8)
    conv8 = BatchNormalization()(conv8)
    conv8 = Activation('relu')(conv8)

    conv8 = Conv3D(filters=filters*2, **params)(conv8)
    conv8 = BatchNormalization()(conv8)
    conv8 = Activation('relu')(conv8)

    up9 = concatenate([UpSampling3D(size=(2, 2, 2))(conv8), x1], axis=-1)
    conv9 = Conv3D(filters=filters, **params)(up9)
    conv9 = BatchNormalization()(conv9)
    conv9 = Activation('relu')(conv9)

    conv9 = Conv3D(filters=filters, **params)(conv9)
    conv9 = BatchNormalization()(conv9)
    conv9 = Activation('relu')(conv9)

    outputs = Conv3D(filters=1, kernel_size=1, kernel_regularizer=l2(1e-4), activation='relu', name='pocket')(conv9)

    model = Model(inputs=inputs, outputs=outputs, name='RAPID_Net')
    return model


def pocket_density_from_mol_RAPID_Net_run1(mol):
    if not isinstance(mol, pybel.Molecule):
        raise TypeError('mol should be a pybel.Molecule object, got %s '
                        'instead' % type(mol))
    if featurizer is None:
        raise ValueError('featurizer must be set to make predistions for '
                         'molecules')
    if scale is None:
        raise ValueError('scale must be set to make predistions')
    prot_coords, prot_features = featurizer.get_features(mol)
    centroid = prot_coords.mean(axis=0)
    prot_coords -= centroid


    resolution = 1. / scale
    x = make_grid(prot_coords, prot_features,
                              max_dist= max_dist,
                              grid_resolution=resolution)
    density = RAPID_Net_run1.predict(x)

    origin = (centroid - max_dist)
    step = np.array([1.0 / scale] * 3)

    return density, origin, step

def pocket_density_from_mol_RAPID_Net_run2(mol):
    if not isinstance(mol, pybel.Molecule):
        raise TypeError('mol should be a pybel.Molecule object, got %s '
                        'instead' % type(mol))
    if featurizer is None:
        raise ValueError('featurizer must be set to make predistions for '
                         'molecules')
    if scale is None:
        raise ValueError('scale must be set to make predistions')
    prot_coords, prot_features = featurizer.get_features(mol)
    centroid = prot_coords.mean(axis=0)
    prot_coords -= centroid


    resolution = 1. / scale
    x = make_grid(prot_coords, prot_features,
                              max_dist= max_dist,
                              grid_resolution=resolution)
    density = RAPID_Net_run2.predict(x)

    origin = (centroid - max_dist)
    step = np.array([1.0 / scale] * 3)

    return density, origin, step

def pocket_density_from_mol_RAPID_Net_run3(mol):
    if not isinstance(mol, pybel.Molecule):
        raise TypeError('mol should be a pybel.Molecule object, got %s '
                        'instead' % type(mol))
    if featurizer is None:
        raise ValueError('featurizer must be set to make predistions for '
                         'molecules')
    if scale is None:
        raise ValueError('scale must be set to make predistions')
    prot_coords, prot_features = featurizer.get_features(mol)
    centroid = prot_coords.mean(axis=0)
    prot_coords -= centroid


    resolution = 1. / scale
    x = make_grid(prot_coords, prot_features,
                              max_dist= max_dist,
                              grid_resolution=resolution)
    density = RAPID_Net_run3.predict(x)

    origin = (centroid - max_dist)
    step = np.array([1.0 / scale] * 3)

    return density, origin, step

def pocket_density_from_mol_RAPID_Net_run4(mol):
    if not isinstance(mol, pybel.Molecule):
        raise TypeError('mol should be a pybel.Molecule object, got %s '
                        'instead' % type(mol))
    if featurizer is None:
        raise ValueError('featurizer must be set to make predistions for '
                         'molecules')
    if scale is None:
        raise ValueError('scale must be set to make predistions')
    prot_coords, prot_features = featurizer.get_features(mol)
    centroid = prot_coords.mean(axis=0)
    prot_coords -= centroid


    resolution = 1. / scale
    x = make_grid(prot_coords, prot_features,
                              max_dist= max_dist,
                              grid_resolution=resolution)
    density = RAPID_Net_run4.predict(x)

    origin = (centroid - max_dist)
    step = np.array([1.0 / scale] * 3)

    return density, origin, step

def pocket_density_from_mol_RAPID_Net_run5(mol):
    if not isinstance(mol, pybel.Molecule):
        raise TypeError('mol should be a pybel.Molecule object, got %s '
                        'instead' % type(mol))
    if featurizer is None:
        raise ValueError('featurizer must be set to make predistions for '
                         'molecules')
    if scale is None:
        raise ValueError('scale must be set to make predistions')
    prot_coords, prot_features = featurizer.get_features(mol)
    centroid = prot_coords.mean(axis=0)
    prot_coords -= centroid


    resolution = 1. / scale
    x = make_grid(prot_coords, prot_features,
                              max_dist= max_dist,
                              grid_resolution=resolution)
    density = RAPID_Net_run5.predict(x)

    origin = (centroid - max_dist)
    step = np.array([1.0 / scale] * 3)

    return density, origin, step

from skimage.morphology import closing, label
from skimage.segmentation import clear_border
import numpy as np
import scipy.ndimage as ndi
import matplotlib.pyplot as plt

def minimal_pockets_segmentation(density1, density2, density3, density4, density5, threshold=threshold_input, min_size=10, scale=0.5, voters = min_vote_minimal):

    voxel_size = (1 / scale) ** 3

    bw1 = closing((density1[0] > threshold).any(axis=-1))
    bw2 = closing((density2[0] > threshold).any(axis=-1))
    bw3 = closing((density3[0] > threshold).any(axis=-1))
    bw4 = closing((density4[0] > threshold).any(axis=-1))
    bw5 = closing((density5[0] > threshold).any(axis=-1))


    # Minimally-reported pockets, voted by at least one model
    combined_bw = np.sum([bw1, bw2, bw3, bw4, bw5], axis=0) >= voters

    # Apply morphological closing to reduce fragmentation
    combined_bw = ndi.binary_closing(combined_bw, structure=np.ones((3, 3, 3)))

    # Clear boundary-connected regions
    cleared = clear_border(combined_bw)

    # Label connected regions
    label_image, num_labels = label(cleared, return_num=True)

    for i in range(1, num_labels + 1):
        pocket_idx = (label_image == i)
        pocket_size = pocket_idx.sum() * voxel_size
        if pocket_size < min_size:
            label_image[np.where(pocket_idx)] = 0

    return label_image

def ensembled_pockets_segmentation(density1, density2, density3, density4, density5, threshold=threshold_input, min_size=50, scale=0.5, voters = min_vote_majority):

    voxel_size = (1 / scale) ** 3

    bw1 = closing((density1[0] > threshold).any(axis=-1))
    bw2 = closing((density2[0] > threshold).any(axis=-1))
    bw3 = closing((density3[0] > threshold).any(axis=-1))
    bw4 = closing((density4[0] > threshold).any(axis=-1))
    bw5 = closing((density5[0] > threshold).any(axis=-1))

    # Majority-voted pockets, predicted by at least 3 models.
    combined_bw = np.sum([bw1, bw2, bw3, bw4, bw5], axis=0) >= voters

    # Apply morphological closing to reduce fragmentation
    combined_bw = ndi.binary_closing(combined_bw, structure=np.ones((3, 3, 3)))

    cleared = clear_border(combined_bw)

    label_image, num_labels = label(cleared, return_num=True)

    for i in range(1, num_labels + 1):
        pocket_idx = (label_image == i)
        pocket_size = pocket_idx.sum() * voxel_size
        if pocket_size < min_size:
            label_image[np.where(pocket_idx)] = 0

    return label_image


def save_pocket_mol2_RAPID_Net_Majority(mol, path, format, **pocket_kwargs):

    density1, origin1, step1 = pocket_density_from_mol_RAPID_Net_run1(mol)
    density1 = np.clip(density1, 0, 1)

    density2, origin2, step2 = pocket_density_from_mol_RAPID_Net_run2(mol)
    density2 = np.clip(density2, 0, 1)

    density3, origin3, step3 = pocket_density_from_mol_RAPID_Net_run3(mol)
    density3 = np.clip(density3, 0, 1)

    density4, origin4, step4 = pocket_density_from_mol_RAPID_Net_run4(mol)
    density4 = np.clip(density4, 0, 1)

    density5, origin5, step5 = pocket_density_from_mol_RAPID_Net_run5(mol)
    density5 = np.clip(density5, 0, 1)

    pockets = ensembled_pockets_segmentation(density1, density2, density3, density4, density5, threshold=threshold_input, min_size=50, scale=0.5, voters = min_vote_majority)

    i = 0
    for pocket_label in range(1, pockets.max() + 1):
        indices = np.argwhere(pockets == pocket_label).astype('float')
        indices *= step1
        indices += origin1
        mol = openbabel.OBMol()
        for idx in indices:
            a = mol.NewAtom()
            a.SetVector(float(idx[0]), float(idx[1]), float(idx[2]))
        p_mol = pybel.Molecule(mol)


        # Formatting threshold (e.g., 0.5 ‚Üí 05, 0.25 ‚Üí 025)
        threshold_str = f"{threshold_input:.2f}".replace(".", "")
        p_mol.write(format, f"{path}/pocket_thr{threshold_str}_Majority{i}.{format}")

        i += 1

def save_pocket_mol2_RAPID_Net_Minimal(mol, path, format, **pocket_kwargs):

    density1, origin1, step1 = pocket_density_from_mol_RAPID_Net_run1(mol)
    density1 = np.clip(density1, 0, 1)

    density2, origin2, step2 = pocket_density_from_mol_RAPID_Net_run2(mol)
    density2 = np.clip(density2, 0, 1)

    density3, origin3, step3 = pocket_density_from_mol_RAPID_Net_run3(mol)
    density3 = np.clip(density3, 0, 1)

    density4, origin4, step4 = pocket_density_from_mol_RAPID_Net_run4(mol)
    density4 = np.clip(density4, 0, 1)

    density5, origin5, step5 = pocket_density_from_mol_RAPID_Net_run5(mol)
    density5 = np.clip(density5, 0, 1)

    pockets = minimal_pockets_segmentation(density1, density2, density3, density4, density5, threshold=threshold_input, min_size=10, scale=0.5, voters = min_vote_minimal)

    i = 0
    for pocket_label in range(1, pockets.max() + 1):
        indices = np.argwhere(pockets == pocket_label).astype('float')
        indices *= step1
        indices += origin1
        mol = openbabel.OBMol()
        for idx in indices:
            a = mol.NewAtom()
            a.SetVector(float(idx[0]), float(idx[1]), float(idx[2]))
        p_mol = pybel.Molecule(mol)

        # Formatting threshold (e.g., 0.5 ‚Üí 05, 0.25 ‚Üí 025)
        threshold_str = f"{threshold_input:.2f}".replace(".", "")
        p_mol.write(format, f"{path}/pocket_thr{threshold_str}_Minimal{i}.{format}")

        i += 1

def save_pocket_mol2_RAPID_Net_Combined(mol, path, format, **pocket_kwargs):
    # Combined function to predict both majority-voted and minority-reported pockets.
    density1, origin1, step1 = pocket_density_from_mol_RAPID_Net_run1(mol)
    density1 = np.clip(density1, 0, 1)

    density2, origin2, step2 = pocket_density_from_mol_RAPID_Net_run2(mol)
    density2 = np.clip(density2, 0, 1)

    density3, origin3, step3 = pocket_density_from_mol_RAPID_Net_run3(mol)
    density3 = np.clip(density3, 0, 1)

    density4, origin4, step4 = pocket_density_from_mol_RAPID_Net_run4(mol)
    density4 = np.clip(density4, 0, 1)

    density5, origin5, step5 = pocket_density_from_mol_RAPID_Net_run5(mol)
    density5 = np.clip(density5, 0, 1)

    pockets_majority = ensembled_pockets_segmentation(density1, density2, density3, density4, density5, threshold=threshold_input, min_size=50, scale=0.5, voters = min_vote_majority)
    pockets_minimal = minimal_pockets_segmentation(density1, density2, density3, density4, density5, threshold=threshold_input, min_size=10, scale=0.5, voters = min_vote_minimal)

    def save_pockets(pockets, label):
        i = 0
        for pocket_label in range(1, pockets.max() + 1):
            indices = np.argwhere(pockets == pocket_label).astype('float')
            indices *= step1
            indices += origin1
            mol = openbabel.OBMol()
            for idx in indices:
                a = mol.NewAtom()
                a.SetVector(float(idx[0]), float(idx[1]), float(idx[2]))
            p_mol = pybel.Molecule(mol)

            # Formatting threshold (e.g., 0.5 ‚Üí 05, 0.25 ‚Üí 025)
            threshold_str = f"{threshold_input:.2f}".replace(".", "")
            p_mol.write(format, f"{path}/pocket_thr{threshold_str}_{label}{i}.{format}")
            i += 1

    # Save both types of pockets
    save_pockets(pockets_majority, "Majority")
    save_pockets(pockets_minimal, "Minimal")

def count_atoms_in_pdb(file_path):
    """Count atoms in PDB file to erase empty pockets"""
    with open(file_path, 'r') as f:
        lines = f.readlines()
    return sum(1 for line in lines if line.startswith("ATOM") or line.startswith("HETATM"))

def calculate_distance(atom1, atom2):
    """Calculates the distance between two atoms."""
    coord1 = np.array(atom1.get_coord())
    coord2 = np.array(atom2.get_coord())
    return np.linalg.norm(coord1 - coord2)

def is_within_distance(protein_atoms, pocket_file, distance_threshold=20.0):
    """
    Checks if every atom in the pocket file is within 'distance_threshold' √Ö
    of at least one atom in the list of 'protein_atoms'.
    If any pocket atom is farther than 'distance_threshold' √Ö from all protein atoms,
    return False.
    """
    parser = PDBParser(QUIET=True)
    pocket_structure = parser.get_structure("Pocket", pocket_file)

    for pocket_model in pocket_structure:
        for pocket_chain in pocket_model:
            for pocket_residue in pocket_chain:
                for pocket_atom in pocket_residue:
                    # Check if this pocket_atom is within the threshold for ANY protein atom
                    within_threshold = any(
                        calculate_distance(pocket_atom, protein_atom) <= distance_threshold
                        for protein_atom in protein_atoms
                    )
                    if not within_threshold:
                        # Found a pocket atom that is NOT within threshold of any protein atom
                        return False

    # If we never returned False, it means all pocket atoms were within threshold
    return True

def remove_invalid_pockets(protein_file, folder_path, distance_threshold=8.0):
    """Removes empty pockets and those beyond the distance threshold from the protein."""
    parser = PDBParser(QUIET=True)
    protein_structure = parser.get_structure("Protein", protein_file)

    # Extract all protein atoms
    protein_atoms = [atom for model in protein_structure
                     for chain in model
                     for residue in chain
                     for atom in residue]

    remaining_pocket_files = []

    for file_name in os.listdir(folder_path):
        if file_name.startswith("pocket") and file_name.endswith(".pdb"):
            pocket_file_path = os.path.join(folder_path, file_name)

            # Check if the file is empty (zero atoms)
            if count_atoms_in_pdb(pocket_file_path) == 0:
                os.remove(pocket_file_path)
                print(f"Deleted empty pocket file: {file_name}")
                continue

            # Check if the file is within the required distance
            if not is_within_distance(protein_atoms, pocket_file_path, distance_threshold):
                os.remove(pocket_file_path)
                print(f"Removed junk: {file_name}")
            else:
                remaining_pocket_files.append(pocket_file_path)
                print(f"Retained pocket file: {file_name}")

    print("\nFinal list of retained pocket files:")
    for file in remaining_pocket_files:
        print(file)


# Featurizer from tfbio package
# https://gitlab.com/cheminfIBB/tfbio
import os
import numpy as np
import py3Dmol
import scipy.stats as stats
import scipy.cluster.hierarchy
from scipy.spatial.distance import squareform
from scipy.interpolate import griddata

import matplotlib.pyplot as plt
import seaborn as sb
from matplotlib import colors

from rdkit import Chem
from rdkit.Chem import AllChem, Draw, rdMolTransforms, rdDepictor, rdForceFieldHelpers
from rdkit.Chem.Draw import rdMolDraw2D, IPythonConsole
from IPython.display import SVG, Image
import ipywidgets as widgets

from openbabel import pybel

import pickle
from math import ceil, sin, cos, sqrt, pi
from itertools import combinations

from statistics import mean, stdev

class Featurizer():
    """Calcaulates atomic features for molecules. Features can encode atom type,
    native pybel properties or any property defined with SMARTS patterns

    Attributes
    ----------
    FEATURE_NAMES: list of strings
        Labels for features (in the same order as features)
    NUM_ATOM_CLASSES: int
        Number of atom codes
    ATOM_CODES: dict
        Dictionary mapping atomic numbers to codes
    NAMED_PROPS: list of string
        Names of atomic properties to retrieve from pybel.Atom object
    CALLABLES: list of callables
        Callables used to calculcate custom atomic properties
    SMARTS: list of SMARTS strings
        SMARTS patterns defining additional atomic properties
    """

    def __init__(self, atom_codes=None, atom_labels=None,
                 named_properties=None, save_molecule_codes=True,
                 custom_properties=None, smarts_properties=None,
                 smarts_labels=None):

        """Creates Featurizer with specified types of features. Elements of a
        feature vector will be in a following order: atom type encoding
        (defined by atom_codes), Pybel atomic properties (defined by
        named_properties), molecule code (if present), custom atomic properties
        (defined `custom_properties`), and additional properties defined with
        SMARTS (defined with `smarts_properties`).

        Parameters
        ----------
        atom_codes: dict, optional
            Dictionary mapping atomic numbers to codes. It will be used for
            one-hot encoging therefore if n different types are used, codes
            shpuld be from 0 to n-1. Multiple atoms can have the same code,
            e.g. you can use {6: 0, 7: 1, 8: 1} to encode carbons with [1, 0]
            and nitrogens and oxygens with [0, 1] vectors. If not provided,
            default encoding is used.
        atom_labels: list of strings, optional
            Labels for atoms codes. It should have the same length as the
            number of used codes, e.g. for `atom_codes={6: 0, 7: 1, 8: 1}` you
            should provide something like ['C', 'O or N']. If not specified
            labels 'atom0', 'atom1' etc are used. If `atom_codes` is not
            specified this argument is ignored.
        named_properties: list of strings, optional
            Names of atomic properties to retrieve from pybel.Atom object. If
            not specified ['hyb', 'heavyvalence', 'heterovalence',
            'partialcharge'] is used.
        save_molecule_codes: bool, optional (default True)
            If set to True, there will be an additional feature to save
            molecule code. It is usefeul when saving molecular complex in a
            single array.
        custom_properties: list of callables, optional
            Custom functions to calculate atomic properties. Each element of
            this list should be a callable that takes pybel.Atom object and
            returns a float. If callable has `__name__` property it is used as
            feature label. Otherwise labels 'func<i>' etc are used, where i is
            the index in `custom_properties` list.
        smarts_properties: list of strings, optional
            Additional atomic properties defined with SMARTS patterns. These
            patterns should match a single atom. If not specified, deafult
            patterns are used.
        smarts_labels: list of strings, optional
            Labels for properties defined with SMARTS. Should have the same
            length as `smarts_properties`. If not specified labels 'smarts0',
            'smarts1' etc are used. If `smarts_properties` is not specified
            this argument is ignored.
        """

        # Remember namse of all features in the correct order
        self.FEATURE_NAMES = []

        if atom_codes is not None:
            if not isinstance(atom_codes, dict):
                raise TypeError('Atom codes should be dict, got %s instead'
#                                 % type(atom_codes))
            codes = set(atom_codes.values())
            for i in range(len(codes)):
                if i not in codes:
                    raise ValueError('Incorrect atom code %s' % i)

            self.NUM_ATOM_CLASSES = len(codes)
            self.ATOM_CODES = atom_codes
            if atom_labels is not None:
                if len(atom_labels) != self.NUM_ATOM_CLASSES:
                    raise ValueError('Incorrect number of atom labels: '
                                     '%s instead of %s'
#                                      % (len(atom_labels), self.NUM_ATOM_CLASSES))
            else:
                atom_labels = ['atom%s' % i for i in range(self.NUM_ATOM_CLASSES)]
            self.FEATURE_NAMES += atom_labels
        else:
            self.ATOM_CODES = {}

            metals = ([3, 4, 11, 12, 13] + list(range(19, 32))
                      + list(range(37, 51)) + list(range(55, 84))
                      + list(range(87, 104)))

            # List of tuples (atomic_num, class_name) with atom types to encode.
            atom_classes = [
                (5, 'B'),
                (6, 'C'),
                (7, 'N'),
                (8, 'O'),
                (15, 'P'),
                (16, 'S'),
                (34, 'Se'),
                ([9, 17, 35, 53], 'halogen'),
                (metals, 'metal')
            ]

            for code, (atom, name) in enumerate(atom_classes):
                if type(atom) is list:
                    for a in atom:
                        self.ATOM_CODES[a] = code
                else:
                    self.ATOM_CODES[atom] = code
                self.FEATURE_NAMES.append(name)

            self.NUM_ATOM_CLASSES = len(atom_classes)

        if named_properties is not None:
            if not isinstance(named_properties, (list, tuple, np.ndarray)):
                raise TypeError('named_properties must be a list')
            allowed_props = [prop for prop in dir(pybel.Atom)
                             if not prop.startswith('__')]
            for prop_id, prop in enumerate(named_properties):
                if prop not in allowed_props:
                    raise ValueError(
                        'named_properties must be in pybel.Atom attributes,'
                        ' %s was given at position %s' % (prop_id, prop)
                    )
            self.NAMED_PROPS = named_properties
        else:
            # pybel.Atom properties to save
            self.NAMED_PROPS = ['hyb', 'heavydegree', 'heterodegree',
                                'partialcharge']
        self.FEATURE_NAMES += self.NAMED_PROPS

        if not isinstance(save_molecule_codes, bool):
            raise TypeError('save_molecule_codes should be bool, got %s '
                            'instead' % type(save_molecule_codes))
        self.save_molecule_codes = save_molecule_codes
        if save_molecule_codes:
            # Remember if an atom belongs to the ligand or to the protein
            self.FEATURE_NAMES.append('molcode')

        self.CALLABLES = []
        if custom_properties is not None:
            for i, func in enumerate(custom_properties):
                if not callable(func):
                    raise TypeError('custom_properties should be list of'
                                    ' callables, got %s instead' % type(func))
                name = getattr(func, '__name__', '')
                if name == '':
                    name = 'func%s' % i
                self.CALLABLES.append(func)
                self.FEATURE_NAMES.append(name)

        if smarts_properties is None:
            # SMARTS definition for other properties
            self.SMARTS = [
                '[#6+0!$(*~[#7,#8,F]),SH0+0v2,s+0,S^3,Cl+0,Br+0,I+0]',
                '[a]',
                '[!$([#1,#6,F,Cl,Br,I,o,s,nX3,#7v5,#15v5,#16v4,#16v6,*+1,*+2,*+3])]',
                '[!$([#6,H0,-,-2,-3]),$([!H0;#7,#8,#9])]',
                '[r]'
            ]
            smarts_labels = ['hydrophobic', 'aromatic', 'acceptor', 'donor',
                             'ring']
        elif not isinstance(smarts_properties, (list, tuple, np.ndarray)):
            raise TypeError('smarts_properties must be a list')
        else:
            self.SMARTS = smarts_properties

        if smarts_labels is not None:
            if len(smarts_labels) != len(self.SMARTS):
                raise ValueError('Incorrect number of SMARTS labels: %s'
                                 ' instead of %s'
#                                  % (len(smarts_labels), len(self.SMARTS)))
        else:
            smarts_labels = ['smarts%s' % i for i in range(len(self.SMARTS))]

        # Compile patterns
        self.compile_smarts()
        self.FEATURE_NAMES += smarts_labels

    def compile_smarts(self):
        self.__PATTERNS = []
        for smarts in self.SMARTS:
            self.__PATTERNS.append(pybel.Smarts(smarts))

    def encode_num(self, atomic_num):
        """Encode atom type with a binary vector. If atom type is not included in
        the `atom_classes`, its encoding is an all-zeros vector.

        Parameters
        ----------
        atomic_num: int
            Atomic number

        Returns
        -------
        encoding: np.ndarray
            Binary vector encoding atom type (one-hot or null).
        """

        if not isinstance(atomic_num, int):
            raise TypeError('Atomic number must be int, %s was given'
#                             % type(atomic_num))

        encoding = np.zeros(self.NUM_ATOM_CLASSES)
        try:
            encoding[self.ATOM_CODES[atomic_num]] = 1.0
        except:
            pass
        return encoding

    def find_smarts(self, molecule):
        """Find atoms that match SMARTS patterns.

        Parameters
        ----------
        molecule: pybel.Molecule

        Returns
        -------
        features: np.ndarray
            NxM binary array, where N is the number of atoms in the `molecule`
            and M is the number of patterns. `features[i, j]` == 1.0 if i'th
            atom has j'th property
        """

        if not isinstance(molecule, pybel.Molecule):
            raise TypeError('molecule must be pybel.Molecule object, %s was given'
#                             % type(molecule))

        features = np.zeros((len(molecule.atoms), len(self.__PATTERNS)))

        for (pattern_id, pattern) in enumerate(self.__PATTERNS):
            atoms_with_prop = np.array(list(*zip(*pattern.findall(molecule))),
                                       dtype=int) - 1
            features[atoms_with_prop, pattern_id] = 1.0
        return features

    def get_features(self, molecule, molcode=None):
        """Get coordinates and features for all heavy atoms in the molecule.

        Parameters
        ----------
        molecule: pybel.Molecule
        molcode: float, optional
            Molecule type. You can use it to encode whether an atom belongs to
            the ligand (1.0) or to the protein (-1.0) etc.

        Returns
        -------
        coords: np.ndarray, shape = (N, 3)
            Coordinates of all heavy atoms in the `molecule`.
        features: np.ndarray, shape = (N, F)
            Features of all heavy atoms in the `molecule`: atom type
            (one-hot encoding), pybel.Atom attributes, type of a molecule
            (e.g protein/ligand distinction), and other properties defined with
            SMARTS patterns
        """

        if not isinstance(molecule, pybel.Molecule):
            raise TypeError('molecule must be pybel.Molecule object,'
                            ' %s was given' % type(molecule))
        if molcode is None:
            if self.save_molecule_codes is True:
                raise ValueError('save_molecule_codes is set to True,'
                                 ' you must specify code for the molecule')
        elif not isinstance(molcode, (float, int)):
            raise TypeError('motlype must be float, %s was given'
#                             % type(molcode))

        coords = []
        features = []
        heavy_atoms = []

        for i, atom in enumerate(molecule):
            # ignore hydrogens and dummy atoms (they have atomicnum set to 0)
            if atom.atomicnum > 1:
                heavy_atoms.append(i)
                coords.append(atom.coords)

                features.append(np.concatenate((
                    self.encode_num(atom.atomicnum),
                    [atom.__getattribute__(prop) for prop in self.NAMED_PROPS],
                    [func(atom) for func in self.CALLABLES],
                )))

        coords = np.array(coords, dtype=np.float32)
        features = np.array(features, dtype=np.float32)
        if self.save_molecule_codes:
            features = np.hstack((features,
                                  molcode * np.ones((len(features), 1))))
        features = np.hstack([features,
                              self.find_smarts(molecule)[heavy_atoms]])

        if np.isnan(features).any():
            raise RuntimeError('Got NaN when calculating features')

        return coords, features

    def to_pickle(self, fname='featurizer.pkl'):
        """Save featurizer in a given file. Featurizer can be restored with
        `from_pickle` method.

        Parameters
        ----------
        fname: str, optional
           Path to file in which featurizer will be saved
        """

        # patterns can't be pickled, we need to temporarily remove them
        patterns = self.__PATTERNS[:]
        del self.__PATTERNS
        try:
            with open(fname, 'wb') as f:
                pickle.dump(self, f)
        finally:
            self.__PATTERNS = patterns[:]

    @staticmethod
    def from_pickle(fname):
        """Load pickled featurizer from a given file

        Parameters
        ----------
        fname: str, optional
           Path to file with saved featurizer

        Returns
        -------
        featurizer: Featurizer object
           Loaded featurizer
        """
        with open(fname, 'rb') as f:
            featurizer = pickle.load(f)
        featurizer.compile_smarts()
        return featurizer


def rotation_matrix(axis, theta):
    """Counterclockwise rotation about a given axis by theta radians"""

    if not isinstance(axis, (np.ndarray, list, tuple)):
        raise TypeError('axis must be an array of floats of shape (3,)')
    try:
        axis = np.asarray(axis, dtype=np.float64)
    except ValueError:
        raise ValueError('axis must be an array of floats of shape (3,)')

    if axis.shape != (3,):
        raise ValueError('axis must be an array of floats of shape (3,)')

    if not isinstance(theta, (float, int)):
        raise TypeError('theta must be a float')

    axis = axis / sqrt(np.dot(axis, axis))
    a = cos(theta / 2.0)
    b, c, d = -axis * sin(theta / 2.0)
    aa, bb, cc, dd = a * a, b * b, c * c, d * d
    bc, ad, ac, ab, bd, cd = b * c, a * d, a * c, a * b, b * d, c * d
    return np.array([[aa + bb - cc - dd, 2 * (bc + ad), 2 * (bd - ac)],
                     [2 * (bc - ad), aa + cc - bb - dd, 2 * (cd + ab)],
                     [2 * (bd + ac), 2 * (cd - ab), aa + dd - bb - cc]])


# Create matrices for all possible 90* rotations of a box
ROTATIONS = [rotation_matrix([1, 1, 1], 0)]

# about X, Y and Z - 9 rotations
for a1 in range(3):
    for t in range(1, 4):
        axis = np.zeros(3)
        axis[a1] = 1
        theta = t * pi / 2.0
        ROTATIONS.append(rotation_matrix(axis, theta))

# about each face diagonal - 6 rotations
for (a1, a2) in combinations(range(3), 2):
    axis = np.zeros(3)
    axis[[a1, a2]] = 1.0
    theta = pi
    ROTATIONS.append(rotation_matrix(axis, theta))
    axis[a2] = -1.0
    ROTATIONS.append(rotation_matrix(axis, theta))

# about each space diagonal - 8 rotations
for t in [1, 2]:
    theta = t * 2 * pi / 3
    axis = np.ones(3)
    ROTATIONS.append(rotation_matrix(axis, theta))
    for a1 in range(3):
        axis = np.ones(3)
        axis[a1] = -1
        ROTATIONS.append(rotation_matrix(axis, theta))


def rotate(coords, rotation):
    """Rotate coordinates by a given rotation

    Parameters
    ----------
    coords: array-like, shape (N, 3)
        Arrays with coordinates and features for each atoms.
    rotation: int or array-like, shape (3, 3)
        Rotation to perform. You can either select predefined rotation by
        giving its index or specify rotation matrix.

    Returns
    -------
    coords: np.ndarray, shape = (N, 3)
        Rotated coordinates.
    """

    global ROTATIONS

    if not isinstance(coords, (np.ndarray, list, tuple)):
        raise TypeError('coords must be an array of floats of shape (N, 3)')
    try:
        coords = np.asarray(coords, dtype=np.float64)
    except ValueError:
        raise ValueError('coords must be an array of floats of shape (N, 3)')
    shape = coords.shape
    if len(shape) != 2 or shape[1] != 3:
        raise ValueError('coords must be an array of floats of shape (N, 3)')

    if isinstance(rotation, int):
        if rotation >= 0 and rotation < len(ROTATIONS):
            return np.dot(coords, ROTATIONS[rotation])
        else:
            raise ValueError('Invalid rotation number %s!' % rotation)
    elif isinstance(rotation, np.ndarray) and rotation.shape == (3, 3):
        return np.dot(coords, rotation)

    else:
        raise ValueError('Invalid rotation %s!' % rotation)

def make_grid(coords, features, grid_resolution=1.0, max_dist=10.0):
    """Convert atom coordinates and features represented as 2D arrays into a
    fixed-sized 3D box.

    Parameters
    ----------
    coords, features: array-likes, shape (N, 3) and (N, F)
        Arrays with coordinates and features for each atoms.
    grid_resolution: float, optional
        Resolution of a grid (in Angstroms).
    max_dist: float, optional
        Maximum distance between atom and box center. Resulting box has size of
        2*`max_dist`+1 Angstroms and atoms that are too far away are not
        included.

    Returns
    -------
    coords: np.ndarray, shape = (M, M, M, F)
        4D array with atom properties distributed in 3D space. M is equal to
        2 * `max_dist` / `grid_resolution` + 1
    """

    try:
        coords = np.asarray(coords, dtype=np.float64)
    except ValueError:
        raise ValueError('coords must be an array of floats of shape (N, 3)')
    c_shape = coords.shape
    if len(c_shape) != 2 or c_shape[1] != 3:
        raise ValueError('coords must be an array of floats of shape (N, 3)')

    N = len(coords)
    try:
        features = np.asarray(features, dtype=np.float64)
    except ValueError:
        raise ValueError('features must be an array of floats of shape (N, F)')
    f_shape = features.shape
    if len(f_shape) != 2 or f_shape[0] != N:
        raise ValueError('features must be an array of floats of shape (N, F)')

    if not isinstance(grid_resolution, (float, int)):
        raise TypeError('grid_resolution must be float')
    if grid_resolution <= 0:
        raise ValueError('grid_resolution must be positive')

    if not isinstance(max_dist, (float, int)):
        raise TypeError('max_dist must be float')
    if max_dist <= 0:
        raise ValueError('max_dist must be positive')

    num_features = f_shape[1]
    max_dist = float(max_dist)
    grid_resolution = float(grid_resolution)

    box_size = ceil(2 * max_dist / grid_resolution + 1)

    # move all atoms to the neares grid point
    grid_coords = (coords + max_dist) / grid_resolution
    grid_coords = grid_coords.round().astype(int)

    # remove atoms outside the box
    in_box = ((grid_coords >= 0) & (grid_coords < box_size)).all(axis=1)
    grid = np.zeros((1, box_size, box_size, box_size, num_features),
                    dtype=np.float32)
    for (x, y, z), f in zip(grid_coords[in_box], features[in_box]):
        grid[0, x, y, z] += f

    return grid

featurizer = Featurizer(save_molecule_codes = False)

scale=0.5
max_dist=35
file_format = 'pdb'

grid_resolution=1.0
scale=0.5
grid_size=36

resolution = 1. / scale
print("\nü¶Å Preparing RAPID-Net model for launch...")

# Download model weights
model_files = [
    "Soft_Dice_Relu_5020_Run_1.keras",
    "Soft_Dice_Relu_5020_Run_2.keras",
    "Soft_Dice_Relu_5020_Run_3.keras",
    "Soft_Dice_Relu_5020_Run_4.keras",
    "Soft_Dice_Relu_5020_Run_5.keras"
]

print("üîÑ Downloading model weights from Zenodo...")
for model_file in model_files:
    !wget -q https://zenodo.org/record/14796981/files/{model_file} -O {model_file}
    if os.path.exists(f"/content/{model_file}"):
        print(f"‚úÖ {model_file} downloaded successfully!")
    else:
        print(f"‚ùå Error: {model_file} not found!")

# Initialize RAPID-Net models
print("üîÑ Initializing RAPID-Net model...")
try:
    RAPID_Net_run1 = RAPID_Net()
    RAPID_Net_run2 = RAPID_Net()
    RAPID_Net_run3 = RAPID_Net()
    RAPID_Net_run4 = RAPID_Net()
    RAPID_Net_run5 = RAPID_Net()
    print("‚úÖ RAPID-Net model initialized successfully!")
except Exception as e:
    print(f"‚ùå Error initializing RAPID-Net models: {e}")

# Load weights into the models
print("üîÑ Loading model weights...")
try:
    RAPID_Net_run1.load_weights('/content/Soft_Dice_Relu_5020_Run_1.keras')
    print("‚úÖ Weights loaded for RAPID_Net_run1!")

    RAPID_Net_run2.load_weights('/content/Soft_Dice_Relu_5020_Run_2.keras')
    print("‚úÖ Weights loaded for RAPID_Net_run2!")

    RAPID_Net_run3.load_weights('/content/Soft_Dice_Relu_5020_Run_3.keras')
    print("‚úÖ Weights loaded for RAPID_Net_run3!")

    RAPID_Net_run4.load_weights('/content/Soft_Dice_Relu_5020_Run_4.keras')
    print("‚úÖ Weights loaded for RAPID_Net_run4!")

    RAPID_Net_run5.load_weights('/content/Soft_Dice_Relu_5020_Run_5.keras')
    print("‚úÖ Weights loaded for RAPID_Net_run5!")

    print("\nüéâ RAPID-Net model ü¶Å unleashed and ready for pocket prediction! üöÄ")
except Exception as e:
    print(f"‚ùå Error loading model weights: {e}")

# @title üîç Let's dock **8F4J**, which AlphaFold 3 (AF3) cannot handle as a whole. üß¨ { display-mode: "form" }

from IPython.display import display, Image

print("Let's dock **8F4J**, which AlphaFold 3 (AF3) cannot handle as a whole.")
print("The following screenshot shows the part of AF3 paper we are referring to:")

image_url = "https://github.com/BalytskyiJaroslaw/RAPID-Net/raw/main/Comparison/8F4J_too_large.png"
display(Image(url=image_url, width=800))

print("""
üìö **Reference to AlphaFold 3 (AF3):**
Abramson, J., Adler, J., Dunger, J. *et al.* (2024). "Accurate structure prediction of biomolecular interactions with AlphaFold 3".
*Nature*, 617, 583‚Äì589. [DOI: 10.1038/s41586-024-07487-w](https://doi.org/10.1038/s41586-024-07487-w)

üöÄ Let's proceed with docking 8F4J using a RAPID-Net guided AutoDock Vina that overcomes these limitations.
""")

"""### üî¨ **Download Protein Structures**

- üì• **8F4J Protein:** [Download from Zenodo](https://zenodo.org/records/14969445)  
- üìö **Original PoseBusters Dataset:** [Access on Zenodo](https://zenodo.org/records/8278563)

"""

# @title **üõ† Create a Repository for Your Protein, Predict Pockets, and Prepare Protein for Docking** { display-mode: "form" }
# @markdown Enter the **protein name** and upload the file.

# @markdown In this case, it is **8F4J_PHO_protein.pdb**

from pymol import cmd

Job_name = "8F4J"  # @param {type: "string"}

import os
import time
from google.colab import files
from openbabel import pybel

Prediction_Type = "Both"  # @param ["Majority", "Minimal", "Both"]

import os
import time
from google.colab import files
from openbabel import pybel

# Ensure a valid name is provided
invalid_chars = '^<>/\\{}[]~`$ '
assert Job_name, '‚ö†Ô∏è Please provide a name for the protein!'
assert not set(invalid_chars).intersection(Job_name), '‚ö†Ô∏è Name contains disallowed characters!'

# Create the protein repository (directory)
WRK_DIR = os.path.join(os.getcwd(), Job_name)
os.makedirs(WRK_DIR, exist_ok=True)

print("\n" + "="*50)
print(f"‚úÖ Protein Repository Created: `{Job_name}`")
print(f"üìÇ Directory: `{WRK_DIR}`")
print("="*50)

# Upload protein file
print("\nüì§ Please upload your protein file:")
uploaded = files.upload()

# Move uploaded file to the created directory
uploaded_filename = list(uploaded.keys())[0]  # Ensure only one file is processed
file_path = os.path.join(WRK_DIR, uploaded_filename)
os.rename(uploaded_filename, file_path)

print("\n" + "-"*50)
print(f"‚úÖ File Uploaded Successfully!")
print(f"üìÑ File Name: `{uploaded_filename}`")
print(f"üìÅ Stored in: `{WRK_DIR}`")
print("-"*50)

# Define paths and formats
protein_file = os.path.join(WRK_DIR, uploaded_filename)
file_format = 'pdb'
output_format = 'pdb'

print("\n‚è≥ Processing Protein File... Please wait.")
time.sleep(1)

# Read the molecular structure
try:
    protein_mol = next(pybel.readfile(file_format, protein_file))
    print("‚úÖ Molecule successfully loaded from the PDB file!")
except Exception as e:
    print(f"‚ùå Error loading molecule: {e}")
    protein_mol = None  # Prevent further processing if failed

# Apply the pocket prediction functions based on user choice
if protein_mol:
    print("\nüîÑ Predicting Pockets...")
    try:
        if Prediction_Type == "Majority":
            save_pocket_mol2_RAPID_Net_Majority(protein_mol, WRK_DIR, output_format)
            print("‚úÖ Majority-voted pockets generated successfully!")
        elif Prediction_Type == "Minimal":
            save_pocket_mol2_RAPID_Net_Minimal(protein_mol, WRK_DIR, output_format)
            print("‚úÖ Minimally-reporting pockets generated successfully!")
        else:
            save_pocket_mol2_RAPID_Net_Combined(protein_mol, WRK_DIR, output_format)
            print("‚úÖ Both Majority and Minimal pockets generated successfully!")

        remove_invalid_pockets(protein_file, WRK_DIR, distance_threshold=20.0)
        print("‚úÖ Invalid pockets filtered out")

        print("\nüéâ Processing Complete! All outputs saved in:")
        print(f"üìÅ `{WRK_DIR}`")
        print("="*50)
    except Exception as e:
        print(f"‚ùå Error during pocket prediction: {e}")


# Function to find the bounding box and generate Vina config file
def process_pocket(pocket_path, pocket_name, thresholds, subfolder_path):
    parser = PDBParser(QUIET=True)
    structure = parser.get_structure(pocket_name, pocket_path)

    # Get all atom coordinates
    atoms = [atom for atom in structure.get_atoms()]
    coords = [atom.coord for atom in atoms]
    coords = np.array(coords)

    max_coords = np.max(coords, axis=0)
    min_coords = np.min(coords, axis=0)

    center = (max_coords + min_coords) / 2

    for threshold in thresholds:
        DELTAx = (max_coords[0] - min_coords[0]) + 2 * threshold
        DELTAy = (max_coords[1] - min_coords[1]) + 2 * threshold
        DELTAz = (max_coords[2] - min_coords[2]) + 2 * threshold

        # Create config content
        config_content = f"""\
center_x = {center[0]}
center_y = {center[1]}
center_z = {center[2]}

size_x = {DELTAx}
size_y = {DELTAy}
size_z = {DELTAz}
"""
        config_filename = f"{pocket_name}_config_{threshold}.txt"
        config_file_path = os.path.join(subfolder_path, config_filename)

        # Write config file
        with open(config_file_path, 'w') as config_file:
            config_file.write(config_content)

        # Create directory for docking results
        result_dir_name = f"{pocket_name}_results_{threshold}"
        result_dir_path = os.path.join(subfolder_path, result_dir_name)
        os.makedirs(result_dir_path, exist_ok=True)

        print(f"Generated config file: {config_file_path}")
        print(f"Created results directory: {result_dir_path}")

# @markdown Specify the search grids.
# @markdown - Provide a **majority_thresholds_input** to have a list of search grids for majority-voted pockets.
# @markdown - Provide a **minority_thresholds_input** to have a list of search grids for majority-voted pockets.

majority_thresholds_input = "2"  # @param {type:"string"}

# Convert input to a list of integers, ignoring invalid entries
majority_thresholds = [int(thr_maj.strip()) for thr_maj in majority_thresholds_input.split(",") if thr_maj.strip().isdigit()]

minority_thresholds_input = ""  # @param {type:"string"}

# Convert input to a list of integers, ignoring invalid entries
minimal_thresholds = [int(thr_min.strip()) for thr_min in minority_thresholds_input.split(",") if thr_min.strip().isdigit()]

minimal_pocket_files = [
    os.path.join(WRK_DIR, file) for file in os.listdir(WRK_DIR)
    if file.startswith("pocket") and "Minimal" in file and file.endswith(".pdb")
]

for pocket_file in minimal_pocket_files:
    pocket_path = os.path.join(WRK_DIR, pocket_file)
    pocket_name = os.path.splitext(pocket_file)[0]
    process_pocket(pocket_path, pocket_name, minimal_thresholds, WRK_DIR)

majority_pocket_files = [
    os.path.join(WRK_DIR, file) for file in os.listdir(WRK_DIR)
    if file.startswith("pocket") and "Majority" in file and file.endswith(".pdb")
]

for pocket_file in majority_pocket_files:
    pocket_path = os.path.join(WRK_DIR, pocket_file)
    pocket_name = os.path.splitext(pocket_file)[0]
    process_pocket(pocket_path, pocket_name, majority_thresholds, WRK_DIR)

def add_hydrogens(input_file, output_file):
    reduce_executable = '/usr/local/bin/reduce'
    het_dict_path = '/usr/local/reduce_wwPDB_het_dict.txt'

    if not os.path.isfile(reduce_executable):
        raise FileNotFoundError(f"Reduce executable not found at {reduce_executable}")

    if not os.path.isfile(het_dict_path):
        raise FileNotFoundError(f"HET dictionary not found at {het_dict_path}")

    reduce_cmd = f"{reduce_executable} -BUILD -DB {het_dict_path} {input_file} > {output_file}"
    try:
        result = subprocess.run(reduce_cmd, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        print(f"Hydrogens added to {input_file} successfully.")
    except subprocess.CalledProcessError as e:
        print(f"Error processing {input_file}: {e}")
        print(f"Standard Output: {e.stdout.decode()}")
        print(f"Standard Error: {e.stderr.decode()}")

import os
import time
import subprocess
from google.colab import files
from pathlib import Path
from openbabel import pybel
from rdkit.Chem import AddHs, MolFromMolFile

# Check if Reduce repository is already cloned
if not os.path.exists("/content/reduce"):
    print("\nüîÑ Installing Reduce and dependencies to add exlicit hydrogens to the protein...")
    subprocess.run("apt-get update && apt-get install -y build-essential cmake", shell=True, check=True)
    subprocess.run("git clone https://github.com/rlabduke/reduce.git", shell=True, check=True)
    subprocess.run("mkdir -p /root/build/reduce && cmake -S /content/reduce -B /root/build/reduce", shell=True, check=True)
    subprocess.run("cmake --build /root/build/reduce --target install", shell=True, check=True)
    subprocess.run("sudo cp /content/reduce/reduce_wwPDB_het_dict.txt /usr/local/reduce_wwPDB_het_dict.txt", shell=True, check=True)
    print("‚úÖ Reduce installed successfully!")
else:
    print("‚úÖ Reduce repository already exists, skipping installation!")


protein_file_reduce = os.path.join(os.path.dirname(protein_file), os.path.basename(protein_file).replace('.pdb', '_reduce.pdb'))
add_hydrogens(protein_file, protein_file_reduce)

print("‚úÖ Protonation completed with Reduce!")

# Define output path for cleaned file
prot_pdb_rm_bad_path = protein_file_reduce.replace("_reduce.pdb", "_reduce_rm_bad.pdb")

# Function to remove unwanted atoms using PyMOL
def _remove_bad_atoms(file_in: str, file_out: str):
    cmd.reinitialize()

    if not os.path.exists(file_in):
        raise FileNotFoundError(f"‚ùå Input file not found: {file_in}")

    print(f"üîÑ Processing {file_in} to remove bad atoms...")

    cmd.load(filename=file_in, object="complex")

    # Remove specific elements
    for element in ["Mo", "B", "Li", "Xe", "As", "Cs", "V", "X"]:
        cmd.remove(f"bymolecule elem {element}")

    # Save the cleaned file
    cmd.save(filename=file_out, selection="complex")

    print(f"‚úÖ Saved cleaned protein to: {file_out}")

# Run bad atom removal
_remove_bad_atoms(protein_file_reduce, prot_pdb_rm_bad_path)

print("‚úÖ Unwanted atoms removed using PyMOL!")

# Convert to PDBQT for docking
prot_pdbqt_file_path = prot_pdb_rm_bad_path.replace("_reduce_rm_bad.pdb", "_reduce_rm_bad_input.pdbqt")
obabel_cmd = f"obabel {prot_pdb_rm_bad_path} -xr -O {prot_pdbqt_file_path} -p 7.4 > /dev/null 2>&1"
subprocess.run(obabel_cmd, shell=True, check=True)
print("‚úÖ Protein PDBQT file generated for docking!")

# @title **üß™ Upload Ligand File & Prepare for Docking ‚öõÔ∏è** { display-mode: "form" }
# @markdown Upload your **ligand starting conformation** for docking.

# @markdown In this case, it is **8F4J_PHO_ligand_start_conf.sdf**

import os
import shutil
from google.colab import files
from rdkit.Chem import MolFromMolFile, AddHs
from meeko import MoleculePreparation

# Upload ligand file
print("\nüì§ Please upload your ligand file (SDF format):")
uploaded = files.upload()

# Ensure only one file is uploaded
lig_sdf_filename = list(uploaded.keys())[0]
uploaded_file_path = os.path.join("/content", lig_sdf_filename)  # File initially goes to /content/

# Move ligand file to the working directory
lig_sdf_file_path = os.path.join(WRK_DIR, lig_sdf_filename)
shutil.move(uploaded_file_path, lig_sdf_file_path)  # Move file
print(f"‚úÖ Ligand moved to working directory: `{lig_sdf_file_path}`")

# Validate file existence
assert os.path.exists(lig_sdf_file_path), f"‚ùå File not found: {lig_sdf_file_path}"

print("\nüîÑ Preparing ligand for docking...")

try:
    # Load ligand using RDKit
    lig = MolFromMolFile(lig_sdf_file_path, sanitize=True)
    if lig is None:
        raise ValueError(f'Failed to load ligand from {lig_sdf_file_path}')
except Exception as e:
    print(f'‚ùå Error loading ligand: {e}')
    print('‚ö†Ô∏è Please ensure the ligand file is a valid SDF format and try again.')
    raise SystemExit

# Ensure ligand has at least one conformer
lig = AddHs(lig, addCoords=True)
assert lig.GetNumConformers() >= 1, "‚ùå Ligand must have at least one conformer!"

# Prepare ligand using Meeko
meeko_prep = MoleculePreparation()
meeko_prep.prepare(lig)

# Define output path in WRK_DIR and save the prepared ligand
lig_pdbqt_file_path = os.path.join(WRK_DIR, lig_sdf_filename.replace('.sdf', '_prepared.pdbqt'))

with open(lig_pdbqt_file_path, 'w') as pdbqt_file:
    pdbqt_file.write(meeko_prep.write_pdbqt_string())

print(f"‚úÖ Ligand prepared and saved in working directory: `{lig_pdbqt_file_path}`")

# @title **üñºÔ∏èüé®üîç Your PB protein (8F4J in this case) with Majority-voted pockets & their labels** { display-mode: "form" }

import py3Dmol
import numpy as np
import os
from Bio.PDB import PDBParser

# Get user input for residues (comma-separated)
residues_input = ""  # @param {type:"string"}

# Convert input to a list of integers, ignoring invalid entries
residues_to_highlight = [int(res.strip()) for res in residues_input.split(",") if res.strip().isdigit()]
highlight_color = "red"

# Find all pocket files in WRK_DIR that match "pocket...Majority...pdb"
cyan_pocket_paths = [
    os.path.join(WRK_DIR, file) for file in os.listdir(WRK_DIR)
    if file.startswith("pocket") and "Majority" in file and file.endswith(".pdb")
]

# Function to compute the geometric center of a residue
def compute_residue_center(residue):
    atom_coords = [atom.coord for atom in residue if atom.element != 'H']
    if atom_coords:
        return np.mean(atom_coords, axis=0)
    return None

# Function to compute the geometric center of an entire pocket
def compute_pocket_center(pocket_path):
    parser = PDBParser(QUIET=True)
    structure = parser.get_structure("pocket", pocket_path)
    coords = []
    for model in structure:
        for chain in model:
            for residue in chain:
                for atom in residue:
                    if atom.element != 'H':
                        coords.append(atom.coord)
    if coords:
        return np.mean(coords, axis=0)
    return None

# Parse the main protein
parser = PDBParser(QUIET=True)
structure = parser.get_structure("protein", protein_file)

residue_centers = {}
for model in structure:
    for chain in model:
        for residue in chain:
            res_id = residue.id[1]
            chain_id = chain.id
            center = compute_residue_center(residue)
            if center is not None:
                residue_centers[(chain_id, res_id)] = center

# Initialize 3D viewer
viewer = py3Dmol.view(width=1500, height=900)

# Load protein structure
with open(protein_file, 'r') as protein_data:
    viewer.addModel(protein_data.read(), 'pdb')
viewer.setStyle({'model': 0}, {"cartoon": {"color": "spectrum"}})

model_index = 1

# Load cyan pockets & label them
for pocket_path in cyan_pocket_paths:
    with open(pocket_path, 'r') as pocket_data:
        viewer.addModel(pocket_data.read(), 'pdb')

    # Style the pocket
    viewer.setStyle(
        {'model': model_index},
        {'stick': {'color': 'cyan', 'radius': 0.1, 'opacity': 0.8}}
    )

    # Compute & label pocket center
    pocket_center = compute_pocket_center(pocket_path)
    if pocket_center is not None:
        x, y, z = map(float, pocket_center)
        pocket_name = os.path.splitext(os.path.basename(pocket_path))[0]  # e.g. "pocket_thr050_Minimal0"

        # Add label (plain text, black, not bold)
        viewer.addLabel(
            pocket_name,
            {
                "position": {"x": x, "y": y, "z": z},
                "fontColor": "black",
                "font": "Helvetica",
                "fontSize": 14,
                "backgroundColor": "white",
                "showBackground": True,
                "opacity": 1.0,
                "inFront": True,
                "screenOffset": {"x": 10, "y": -10}
            }
        )

    model_index += 1

# Highlight selected residues
for (chain_id, res_id), center in residue_centers.items():
    if res_id in residues_to_highlight:
        viewer.addStyle(
            {"chain": chain_id, "resi": res_id},
            {"stick": {"color": highlight_color, "radius": 0.3}}
        )
        res_name = structure[0][chain_id][(' ', res_id, ' ')].resname
        label = f"{res_name}{res_id}"
        x, y, z = map(float, center)
        viewer.addLabel(label, {
            "position": {"x": x, "y": y, "z": z},
            "fontColor": highlight_color,
            "font": "Helvetica",
            "fontSize": 14,
            "backgroundColor": "black",
            "showBackground": True,
            "opacity": 1.0,
            "inFront": True,
            "screenOffset": {"x": 5, "y": -5}
        })

viewer.zoomTo()
viewer.show()

# @title **üñºÔ∏èüé®üîç Your PB protein (8F4J in this case) with Minority-reported pockets & their labels** { display-mode: "form" }

import py3Dmol
import numpy as np
import os
from Bio.PDB import PDBParser

# Get user input for residues (comma-separated)
residues_input = ""  # @param {type:"string"}

# Convert input to a list of integers, ignoring invalid entries
residues_to_highlight = [int(res.strip()) for res in residues_input.split(",") if res.strip().isdigit()]
highlight_color = "red"

# Find all pocket files in WRK_DIR that match "pocket...Majority...pdb"
cyan_pocket_paths = [
    os.path.join(WRK_DIR, file) for file in os.listdir(WRK_DIR)
    if file.startswith("pocket") and "Minimal" in file and file.endswith(".pdb")
]

# Function to compute the geometric center of a residue
def compute_residue_center(residue):
    atom_coords = [atom.coord for atom in residue if atom.element != 'H']
    if atom_coords:
        return np.mean(atom_coords, axis=0)
    return None

# Function to compute the geometric center of an entire pocket
def compute_pocket_center(pocket_path):
    parser = PDBParser(QUIET=True)
    structure = parser.get_structure("pocket", pocket_path)
    coords = []
    for model in structure:
        for chain in model:
            for residue in chain:
                for atom in residue:
                    if atom.element != 'H':
                        coords.append(atom.coord)
    if coords:
        return np.mean(coords, axis=0)
    return None

# Parse the main protein
parser = PDBParser(QUIET=True)
structure = parser.get_structure("protein", protein_file)

residue_centers = {}
for model in structure:
    for chain in model:
        for residue in chain:
            res_id = residue.id[1]
            chain_id = chain.id
            center = compute_residue_center(residue)
            if center is not None:
                residue_centers[(chain_id, res_id)] = center

# Initialize 3D viewer
viewer = py3Dmol.view(width=1500, height=900)

# Load protein structure
with open(protein_file, 'r') as protein_data:
    viewer.addModel(protein_data.read(), 'pdb')
viewer.setStyle({'model': 0}, {"cartoon": {"color": "spectrum"}})

model_index = 1

# Load cyan pockets & label them
for pocket_path in cyan_pocket_paths:
    with open(pocket_path, 'r') as pocket_data:
        viewer.addModel(pocket_data.read(), 'pdb')

    # Style the pocket
    viewer.setStyle(
        {'model': model_index},
        {'stick': {'color': 'purple', 'radius': 0.3, 'opacity': 0.8}}
    )

    # Compute & label pocket center
    pocket_center = compute_pocket_center(pocket_path)
    if pocket_center is not None:
        x, y, z = map(float, pocket_center)
        pocket_name = os.path.splitext(os.path.basename(pocket_path))[0]  # e.g. "pocket_thr050_Minimal0"

        # Add label (plain text, black, not bold)
        viewer.addLabel(
            pocket_name,
            {
                "position": {"x": x, "y": y, "z": z},
                "fontColor": "black",
                "font": "Helvetica",
                "fontSize": 14,
                "backgroundColor": "white",
                "showBackground": True,
                "opacity": 1.0,
                "inFront": True,
                "screenOffset": {"x": 10, "y": -10}
            }
        )

    model_index += 1

# Highlight selected residues
for (chain_id, res_id), center in residue_centers.items():
    if res_id in residues_to_highlight:
        viewer.addStyle(
            {"chain": chain_id, "resi": res_id},
            {"stick": {"color": highlight_color, "radius": 0.3}}
        )
        res_name = structure[0][chain_id][(' ', res_id, ' ')].resname
        label = f"{res_name}{res_id}"
        x, y, z = map(float, center)
        viewer.addLabel(label, {
            "position": {"x": x, "y": y, "z": z},
            "fontColor": highlight_color,
            "font": "Helvetica",
            "fontSize": 14,
            "backgroundColor": "black",
            "showBackground": True,
            "opacity": 1.0,
            "inFront": True,
            "screenOffset": {"x": 5, "y": -5}
        })

viewer.zoomTo()
viewer.show()

# @title **Use üñºÔ∏èüé®üîç LaboDock for illustration** { display-mode: "form" }

# This function was taken from here: https://github.com/RyanZR/labodock


#############################################
# Grid Box Calculation Methods

import os
import numpy as np
from Bio.PDB import PDBParser
import py3Dmol  # for the LaboSpace class usage


class GridBox:

    ranges = tuple[list[float], list[float], list[float]]
    coords = tuple[float, float, float]
    center_bxsize = tuple[tuple[float, float, float], tuple[float, float, float]]

    def __init__(self, inpt_file: str) -> None:
        self.inpt = open(inpt_file, 'r')
        self.data = self.inpt.read()
        self.cmol = Chem.MolFromPDBBlock(self.data)
        self.conf = self.cmol.GetConformer()
        self.ntom = self.cmol.GetNumAtoms()
        self.inpt.close()

    def update_gridbox(self, mol_block: str) -> None:
        self.cmol = Chem.MolFromPDBBlock(mol_block)
        self.conf = self.cmol.GetConformer()
        self.ntom = self.cmol.GetNumAtoms()

    def compute_coords(self) -> ranges:
        x_coord = [self.conf.GetAtomPosition(c).x for c in range(self.ntom)]
        y_coord = [self.conf.GetAtomPosition(c).y for c in range(self.ntom)]
        z_coord = [self.conf.GetAtomPosition(c).z for c in range(self.ntom)]
        return x_coord, y_coord, z_coord

    def compute_ranges(self) -> ranges:
        x, y, z = self.compute_coords()
        x_range = [min(x), max(x)]
        y_range = [min(y), max(y)]
        z_range = [min(z), max(z)]
        return x_range, y_range, z_range

    def compute_center(self, use_range: bool = True) -> coords:
        x, y, z = self.compute_ranges() if use_range else self.compute_coords()
        x_center = round(np.mean(x), 3)
        y_center = round(np.mean(y), 3)
        z_center = round(np.mean(z), 3)
        return x_center, y_center, z_center

    def generate_res_molblock(self, residues_list: list[str]) -> str:
        res_lines = [line for line in self.data.split('\n')
                     if line[22:26].lstrip() in residues_list
                     and 'END' not in line]
        res_block = '\n'.join(res_lines)
        return res_block

    def labox(self, scale: float = 2.0) -> coords:
        xr, yr, zr = self.compute_ranges()
        center = self.compute_center()
        bxsize = (round(abs(xr[0] - xr[1]) * scale, 3),
                  round(abs(yr[0] - yr[1]) * scale, 3),
                  round(abs(zr[0] - zr[1]) * scale, 3))
        return center, bxsize

    def eboxsize(self, gy_box_ratio: float = 0.23, modified: bool = False) -> center_bxsize:
        xc, yc, zc = self.compute_coords()
        center = self.compute_center(modified)
        distsq = [(x-center[0])**2 + (y-center[1])**2 + (z-center[2])**2
                  for x, y, z in zip(xc, yc, zc)]
        bxsize = (round(np.sqrt(sum(distsq) / len(xc)) / gy_box_ratio, 3),) * 3
        return center, bxsize

    def autodock_grid(self) -> center_bxsize:
        xr, yr, zr = self.compute_ranges()
        center = self.compute_center()
        bxsize = (22.5, 22.5, 22.5)
        return center, bxsize

    def defined_by_res(self, residue_number: str, scale: float = 1.25) -> center_bxsize:
        res_list = residue_number.replace(',', ' ').split()
        res_block = self.generate_res_molblock(res_list)
        self.update_gridbox(res_block)
        return self.labox(scale=scale)

#############################################
# RMSD Calculation Methods

class ComputeRMSD:

    def __init__(self) -> None:
        self.MCS_mol = None
        self.MCS_png = None

    def load_molecule(self, inpt_file: str, remove_Hs: bool = True) -> tuple:
        molecule = io.loadmol(inpt_file)
        molecule.strip() if remove_Hs else None
        name = os.path.basename(inpt_file).split('.')[0]
        coor = molecule.coordinates
        anum = molecule.atomicnums
        mtrx = molecule.adjacency_matrix
        cmol = Chem.MolFromPDBFile(inpt_file)
        return name, coor, anum, mtrx, cmol

    def mol_to_png(self, mol: object) -> object:
        legend = 'Maximum Common Substructure'
        png = Draw.MolToImage(mol, legend=legend)
        return png

    def find_MCS(self, ref: tuple, lig: tuple) -> object:
        if self.MCS_mol is None:
            MCS_obj = rdFMCS.FindMCS([ref[4], lig[4]])
            MCS_mol = Chem.MolFromSmarts(MCS_obj.smartsString)
            MCS_png = self.mol_to_png(MCS_mol)
            self.MCS_mol = MCS_mol
            self.MCS_png = MCS_png
        return self.MCS_mol

    def hung_RMSD(self, ref: tuple, lig: tuple) -> float:
        try:
            hRMSD = round(rmsd.hrmsd(ref[1], lig[1], ref[2], lig[2]), 3)
        except:
            hRMSD = 'ERROR'
        return hRMSD

    def symm_RMSD(self, ref: tuple, lig: tuple, minimise: bool = False) -> float:
        try:
            sRMSD = round(rmsd.symmrmsd(ref[1], lig[1], ref[2], lig[2], ref[3], lig[3], minimize=minimise), 3)
        except:
            sRMSD = 'ERROR'
        return sRMSD

    def labo_RMSD(self, ref: tuple, lig: tuple) -> float:
        mol_substr = self.find_MCS(ref, lig)
        ref_substr = ref[4].GetSubstructMatch(mol_substr)
        lig_substr = lig[4].GetSubstructMatch(mol_substr)

        distsq = []
        for ref_atom, lig_atom in zip(ref_substr, lig_substr):
            ref_pos = ref[4].GetConformer().GetAtomPosition(ref_atom)
            lig_pos = lig[4].GetConformer().GetAtomPosition(lig_atom)
            ref_coord = np.array((ref_pos.x, ref_pos.y, ref_pos.z))
            lig_coord = np.array((lig_pos.x, lig_pos.y, lig_pos.z))
            coo_dist = np.linalg.norm(ref_coord - lig_coord)
            distsq.append(coo_dist ** 2)

        try:
            lRMSD = round(np.sqrt(sum(distsq)/len(distsq)), 3)
        except:
            lRMSD = 'ERROR'
        return lRMSD

    def rmsd_report(self,
                    ref: tuple,
                    lig: tuple,
                    lRMSD: bool = True,
                    hRMSD: bool = True,
                    sRMSD: bool = True
                    ) -> dict[str: list[float]]:
        report = {}
        report['NAME'] = [lig[0]]
        report['LABO_RMSD'] = [self.labo_RMSD(ref, lig)] if lRMSD else None
        report['HUNG_RMSD'] = [self.hung_RMSD(ref, lig)] if hRMSD else None
        report['SYMM_RMSD'] = [self.symm_RMSD(ref, lig)] if sRMSD else None
        report = {k: v for k, v in report.items() if v is not None}
        return report

#############################################
# AA Consntant and Bond Colour Dictionary

# Kyte and Doolittle Hydropathy Scale (1982)
AA_HB = {'ALA':  1.8, 'ARG': -4.5, 'ASN': -3.5, 'ASP': -3.5, 'CYS':  2.5,
         'GLN': -3.5, 'GLU': -3.5, 'GLY': -0.4, 'HIS': -3.2, 'ILE':  4.5,
         'LEU':  3.8, 'LYS': -3.9, 'MET':  1.9, 'PHE':  2.8, 'PRO': -1.6,
         'SER': -0.8, 'THR': -0.7, 'TRP': -0.9, 'TYR': -1.3, 'VAL':  4.2}

# University of Calgary PI Scale
AA_PI = {'ALA':  6.0, 'ARG': 10.76, 'ASN': 5.41, 'ASP': 2.77, 'CYS': 5.07,
         'GLN': 5.65, 'GLU':  3.22, 'GLY': 5.97, 'HIS': 7.59, 'ILE': 6.02,
         'LEU': 5.98, 'LYS':  9.74, 'MET': 5.74, 'PHE': 5.48, 'PRO':  6.3,
         'SEC': 5.68, 'SER':  5.68, 'THR':  5.6, 'TRP': 5.89, 'TYR': 5.66,
         'VAL': 5.96}

BOND_COL = {'HYDROPHOBIC': ['0x59e382', 'GREEN'],
            'HBOND': ['0x59bee3', 'LIGHT BLUE'],
            'WATERBRIDGE': ['0x4c4cff', 'BLUE'],
            'SALTBRIDGE': ['0xefd033', 'YELLOW'],
            'PISTACKING': ['0xb559e3', 'PURPLE'],
            'PICATION': ['0xe359d8', 'VIOLET'],
            'HALOGEN': ['0x59bee3', 'LIGHT BLUE'],
            'METAL':['0xe35959', 'ORANGE']}

#############################################
# AA-to-Colour Converter Function

def sequential_gradient(value: float,
                        min_value: float,
                        max_value: float,
                        targ_colour: str = '00ff00',
                        interpolation: float = 0.0
                        ) -> str:
    norm_val = (value - min_value) / (max_value - min_value)

    rgb = tuple(int(targ_colour[d:d+2], 16) for d in (0, 2, 4))
    r = int(255 - (255 - rgb[0]) * (1 - interpolation) * norm_val)
    g = int(255 - (255 - rgb[1]) * (1 - interpolation) * norm_val)
    b = int(255 - (255 - rgb[2]) * (1 - interpolation) * norm_val)

    hex_code = f'#{r:02x}{g:02x}{b:02x}'
    return hex_code

def diverging_gradient(value: float,
                       min_value: float,
                       max_value: float,
                       base_colour: str = 'ff0000',
                       targ_colour: str = '0000ff',
                       interpolation: float = 0.3
                       ) -> str:
    norm_val = (value - min_value) / (max_value - min_value)

    white = (255, 255, 255)
    rgb_A = tuple(int(base_colour[d:d+2], 16) for d in (0, 2, 4))
    rgb_B = tuple(int(targ_colour[d:d+2], 16) for d in (0, 2, 4))

    if norm_val < 0.5 - interpolation / 2:
        factor = norm_val / (0.5 - interpolation / 2)
        r = int(rgb_A[0] + (white[0] - rgb_A[0]) * factor)
        g = int(rgb_A[1] + (white[1] - rgb_A[1]) * factor)
        b = int(rgb_A[2] + (white[2] - rgb_A[2]) * factor)
    elif norm_val > 0.5 + interpolation / 2:
        factor = (norm_val - 0.5 - interpolation / 2) / (0.5 - interpolation / 2)
        r = int(white[0] + (rgb_B[0] - white[0]) * factor)
        g = int(white[1] + (rgb_B[1] - white[1]) * factor)
        b = int(white[2] + (rgb_B[2] - white[2]) * factor)
    else:
        r, g, b = white

    hex_code = f'#{r:02x}{g:02x}{b:02x}'
    return hex_code

def a2c_converter(aa_map: dict, grad_func: 'function') -> dict:
    min_value = min(aa_map.values())
    max_value = max(aa_map.values())
    aa_dict = {aa: grad_func(value, min_value, max_value)
               for aa, value in aa_map.items()}
    return aa_dict

#############################################
# Built-in Styling Function

def builtin_style(style: str, opacity: float = 1.0) -> dict:
    match style:
        case _ if any(kw in style for kw in ('Carbon', 'chain', 'ssJmol', 'ssPyMol')):
            style_dict = {'colorscheme': style}
        case 'hydrophobicity':
            style_dict = {'colorscheme': {
                'prop': 'resn', 'map': a2c_converter(AA_HB, sequential_gradient)}}
        case 'isoelectric points':
            style_dict = {'colorscheme': {
                'prop': 'resn', 'map': a2c_converter(AA_PI, diverging_gradient)}}
        case 'b factor':
            style_dict = {'colorscheme': {
                'prop': 'b', 'gradient': 'rwb', 'min': 90, 'max': 50}}
        case _:
            style_dict = {'color': style}

    style_dict.update({'opacity': opacity, 'singleBonds': False})
    return style_dict

#############################################
# Built-in Colour Scale Function

def colour_scale(aa_map: dict, grad_func: 'function') -> None:
    min_value = min(aa_map.values())
    max_value = max(aa_map.values())

    linear_values = np.linspace(min_value, max_value, 100)
    colours = [grad_func(value, min_value, max_value)
               for value in linear_values]

    fig, ax = plt.subplots(figsize=(4.85, 0.25))
    norm_value = plt.Normalize(min_value, max_value)
    colour_map = plt.cm.colors.ListedColormap(colours)
    scalar_map = plt.cm.ScalarMappable(norm_value, colour_map)
    scalar_map.set_array([])

    cscale = plt.colorbar(scalar_map, ax, orientation='horizontal')
    cscale.set_ticks([min_value, max_value])

def show_cscale(rept_info: dict, surf_info: dict) -> None:

    def cs_selector() -> str:
        if any(surf_info):
            style = [*surf_info.values()][0]
        elif any(rept_info):
            style = [*rept_info.values()][0]
        else:
            style = None
        return style

    def cs_display(style: str):
        if style == 'hydrophobicity':
            label_title(style, 'Less', 'More')
            colour_scale(AA_HB, sequential_gradient)
        elif style == 'isoelectric points':
            label_title(style, 'Acid', 'Base')
            colour_scale(AA_PI, diverging_gradient)
        else:
            pass

    def label_title(text: str, min: str, max: str) -> None:
        print(f'-' * 55)
        print(f'{min}{text.upper():^47}{max}')
        print(f'-' * 55)

    cs_display(cs_selector())

#############################################
# Other Functions

def extract_config(inpt_file: str) -> tuple:
    with open(inpt_file, 'r') as inpt:
        data = [line.split() for line in inpt.readlines()]
    center = (float(data[0][2]), float(data[1][2]), float(data[2][2]))
    bxsize = (float(data[4][2]), float(data[5][2]), float(data[6][2]))
    return center, bxsize

def interaction_dict(inpt_file: str, interactions: str = '', usage: str = 'view' or 'lbsp') -> dict:

    usg_map = {'lbsp': 0, 'view': 1}

    def filter_df(int_df: pd.DataFrame, interactions: list = []) -> pd.DataFrame:
        int_df = int_df[int_df['BOND'].isin(interactions)] if interactions else int_df
        return int_df

    def s2f_dict(item: dict) -> dict:
        return {key: tuple(float(val) for val in value[1:-1].split(','))
                for key, value in item.items()}

    def b2c_dict(item: dict) -> dict:
        return {key: BOND_COL[val][usg_map[usage]] for key, val in item.items()}

    intrxn = interactions.replace(',', ' ').split()
    inter_df = pd.read_csv(inpt_file)
    int_dict = filter_df(inter_df, intrxn).to_dict()
    int_dict['LIGCOO'] = s2f_dict(int_dict['LIGCOO'])
    int_dict['PROTCOO'] = s2f_dict(int_dict['PROTCOO'])
    int_dict['COLOR'] = b2c_dict(int_dict['BOND'])

    return int_dict

def find_midpoint(coords: list) -> tuple[float, float, float]:
    return tuple(round(coord, 3) for coord in np.mean(coords, axis=0))

#############################################
# LaboSpace Viewer

class LaboSpace:

    residue_style = {
        'stick':
         {'colorscheme': 'orangeCarbon', 'radius': 0.15}}
    residue_label = {
        'alignment': 'bottomLeft',
        'showBackground': False,
        'inFront': True,
        'fontSize': 14,
        'fontColor': '0x000000',
        'screenOffset': {'x': 25, 'y': 25}}
    atom_label = {
        'alignment': 'bottomLeft',
        'showBackground': False,
        'inFront': True,
        'fontSize': 14,
        'fontColor': '0x000000',
        'screenOffset': {'x': 10, 'y': 10}}

    def __init__(self, vw: int = 500, vh: int = 500) -> None:
        self.mview = py3Dmol.view(width=vw, height=vh)
        self.count = -1
        self.residues = []

    def read_moldata(self, inpt_file: str) -> str:
        inpt = open(inpt_file, 'r')
        data = inpt.read()
        inpt.close()
        return data

    def load_receptor(self, inpt_file: str) -> object:
        data = self.read_moldata(inpt_file)
        self.mview.addModel(data, 'pdb')
        self.count += 1
        return self

    def load_ligand(self, inpt_file: str) -> object:
        data = self.read_moldata(inpt_file)
        self.mview.addModel(data)
        self.count += 1
        return self

    def set_style(self,
                  show_represent: bool = True,
                  represent_type: str = 'cartoon',
                  represent_style: dict = {}
                  ) -> object:
        if show_represent:
            self.mview.setStyle(
                {'model': self.count},
                {represent_type: represent_style})
        else:
            self.mview.setStyle(
                {'model': self.count},
                {})
        return self

    def add_style(self,
                  show_represent: bool = True,
                  represent_style: dict = {}
                  ) -> object:
        if show_represent:
            self.mview.addStyle(
                {'model': self.count},
                represent_style)
        return self

    def add_residues(self,
                     show_residues: bool = True,
                     residue_number: str = ''
                     ) -> object:
        if show_residues and residue_number:
            res = residue_number.replace(',', ' ').split()
            self.residues.extend(list(set(res)))
            self.mview.addStyle(
                {'and': [{'model': self.count}, {'resi': self.residues}]},
                self.residue_style)
            self.mview.addResLabels(
                {'and': [{'model': self.count}, {'resi': self.residues}]},
                self.residue_label)
        return self

    def add_surface(self,
                    show_surface: bool = True,
                    surface_type: str = 'SES',
                    surface_style: dict = {}
                    ) -> object:
        if show_surface:
            self.mview.addSurface(
                surface_type,
                surface_style,
                {'model': self.count})
        return self

    def add_gridbox(self,
                    show_gridbox: bool,
                    center: list[float],
                    bxsize: list[float]
                    ) -> object:
        if show_gridbox:
            bxi, byi, bzi = center
            bxf, byf, bzf = bxsize
            self.mview.addBox({
                'center': {'x': bxi, 'y': byi, 'z': bzi},
                'dimensions': {'w': bxf, 'h': byf, 'd': bzf},
                'color': 'skyBlue',
                'opacity': 0.6})
            self.mview.addLabel(
                f'center: {bxi:>8}, {byi:>8}, {bzi:>8}',
                {'showBackground': False,
                 'fontSize': 14,
                 'fontColor': '0x000000',
                 'useScreen': True,
                 'screenOffset': {'x': 15, 'y': 0}})
            self.mview.addLabel(
                f'bxsize: {bxf:>8}, {byf:>8}, {bzf:>8}',
                {'showBackground': False,
                 'fontSize': 14,
                 'fontColor': '0x000000',
                 'useScreen': True,
                 'screenOffset': {'x': 15, 'y': -20}})
        return self

    def add_interaction(self,
                        interaction_file: str,
                        show_interaction: bool = True,
                        select_interaction: list = []
                        ) -> object:
        if show_interaction:
            int_dict = interaction_dict(interaction_file, select_interaction, 'lbsp')
            dist = int_dict['DIST'].values()
            bond = int_dict['BOND'].values()
            resn = int_dict['RESNR'].values()
            ligcoo = int_dict['LIGCOO'].values()
            prtcoo = int_dict['PROTCOO'].values()
            color = int_dict['COLOR'].values()

            int_res = list(set(resn) - set(self.residues))
            self.residues.extend(int_res)
            self.mview.addStyle(
                {'and': [{'model': 0}, {'resi': int_res}]},
                self.residue_style)
            self.mview.addResLabels(
                {'and': [{'model': 0}, {'resi': int_res}]},
                self.residue_label)

            for dis, col, lig, prt in zip(dist, color, ligcoo, prtcoo):
                mid = find_midpoint([lig, prt])
                self.mview.addCylinder(
                    {'start': {'x': lig[0], 'y': lig[1], 'z': lig[2]},
                     'end': {'x': prt[0], 'y': prt[1], 'z': prt[2]},
                     'radius': 0.05,
                     'fromCap': 1,
                     'toCap': 1,
                     'color': col,
                     'dashed': True})
                self.mview.addLabel(
                    str(dis) + ' √Ö',
                    {'position': {'x': mid[0], 'y': mid[1], 'z': mid[2]},
                     'alignment': 'bottomLeft',
                     'inFront': False,
                     'backgroundColor': col,
                     'fontSize': 10,
                     'screenOffset': {'x': 10, 'y': 10}})
        return self

    def label_atoms(self, show_label: bool = False) -> object:
        # WARNING: Avoid applying on protein !!!
        if show_label:
            self.mview.addPropertyLabels(
                'atom',
                {'model': self.count},
                self.atom_label)
        return self

    def view_space(self,
                   zoom_model: int = -1,
                   slab_view: bool = False,
                   slab_model: int = -1,
                   background_colour: str = '0xFFFFFF'
                   ) -> None:
        self.mview.setBackgroundColor(background_colour)
        self.mview.setProjection('orthographic')
        self.mview.zoomTo({'model': zoom_model})
        self.mview.fitSlab({'model': slab_model}) if slab_view else None
        self.mview.show()


def compute_box_from_pocket(pocket_path: str, threshold: float):
    """
    Reads the pocket file, parses all atom coordinates, computes the bounding box
    (min and max coords), then inflates each dimension by 2*threshold.
    Returns (center, box_dimensions).
    """
    parser = PDBParser(QUIET=True)
    structure = parser.get_structure("pocket_struct", pocket_path)

    coords = []
    for atom in structure.get_atoms():
        coords.append(atom.coord)
    coords = np.array(coords)

    min_coords = np.min(coords, axis=0)
    max_coords = np.max(coords, axis=0)

    center = (max_coords + min_coords) / 2.0
    size_x = (max_coords[0] - min_coords[0]) + 2 * threshold
    size_y = (max_coords[1] - min_coords[1]) + 2 * threshold
    size_z = (max_coords[2] - min_coords[2]) + 2 * threshold

    return tuple(center), (size_x, size_y, size_z)


# ----------------------------------------------------------------------------
# **User Inputs**
protein_path = protein_file
pocket_path  = "/content/8F4J/pocket_thr050_Majority0.pdb"  # @param {type:"string"}
residues_to_highlight = ""  # @param {type:"string"}
threshold = 2.0  # @param {type:"number"} Each dimension is expanded by +/- threshold √Ö
# ----------------------------------------------------------------------------

# Compute bounding box from pocket
center, bxsize = compute_box_from_pocket(pocket_path, threshold)

# ----- FIX: convert np.float32 or np.float64 -> plain Python float ------
center = tuple(float(c) for c in center)   # ensures JSON serializable
bxsize = tuple(float(s) for s in bxsize)   # ensures JSON serializable
# -----------------------------------------------------------------------

# Create the LaboSpace viewer
LBSP = LaboSpace(1500, 900)

# Load and style the protein (white cartoon)
LBSP.load_receptor(protein_path)\
    .set_style(
        show_represent=True,
        represent_type='cartoon',
        represent_style={'color': 'white'}  # same color style as your snippet
    )\
    .add_residues(
        show_residues=True,
        residue_number=residues_to_highlight
    )

# Load and style the pocket (cyan sticks, radius=0.3, opacity=1)
LBSP.load_ligand(pocket_path)\
    .set_style(
        show_represent=True,
        represent_type='stick',
        represent_style={'color': 'cyan', 'radius': 0.3, 'opacity': 1}
    )

# Add a semi-transparent skyBlue bounding box
LBSP.add_gridbox(
    show_gridbox=True,
    center=center,
    bxsize=bxsize
)

# Add solid black edges around the bounding box
bxi, byi, bzi = center
bxf, byf, bzf = bxsize

edges = [
    # Bottom face
    ((bxi - bxf/2, byi - byf/2, bzi - bzf/2), (bxi + bxf/2, byi - byf/2, bzi - bzf/2)),
    ((bxi - bxf/2, byi - byf/2, bzi - bzf/2), (bxi - bxf/2, byi + byf/2, bzi - bzf/2)),
    ((bxi + bxf/2, byi + byf/2, bzi - bzf/2), (bxi + bxf/2, byi - byf/2, bzi - bzf/2)),
    ((bxi + bxf/2, byi + byf/2, bzi - bzf/2), (bxi - bxf/2, byi + byf/2, bzi - bzf/2)),

    # Top face
    ((bxi - bxf/2, byi - byf/2, bzi + bzf/2), (bxi + bxf/2, byi - byf/2, bzi + bzf/2)),
    ((bxi - bxf/2, byi - byf/2, bzi + bzf/2), (bxi - bxf/2, byi + byf/2, bzi + bzf/2)),
    ((bxi + bxf/2, byi + byf/2, bzi + bzf/2), (bxi + bxf/2, byi - byf/2, bzi + bzf/2)),
    ((bxi + bxf/2, byi + byf/2, bzi + bzf/2), (bxi - bxf/2, byi + byf/2, bzi + bzf/2)),

    # Vertical edges connecting top & bottom
    ((bxi - bxf/2, byi - byf/2, bzi - bzf/2), (bxi - bxf/2, byi - byf/2, bzi + bzf/2)),
    ((bxi + bxf/2, byi - byf/2, bzi - bzf/2), (bxi + bxf/2, byi - byf/2, bzi + bzf/2)),
    ((bxi - bxf/2, byi + byf/2, bzi - bzf/2), (bxi - bxf/2, byi + byf/2, bzi + bzf/2)),
    ((bxi + bxf/2, byi + byf/2, bzi - bzf/2), (bxi + bxf/2, byi + byf/2, bzi + bzf/2))
]

for start, end in edges:
    LBSP.mview.addCylinder({
        'start': {'x': start[0], 'y': start[1], 'z': start[2]},
        'end':   {'x': end[0],   'y': end[1],   'z': end[2]},
        'radius': 0.05,
        'color': 'black',
        'opacity': 1.0
    })

# Display the final result
LBSP.view_space(
    zoom_model=-1,
    slab_view=False,
    slab_model=-1,
    background_colour='0xFFFFFF'
)

# Commented out IPython magic to ensure Python compatibility.
#@title **üöÄ Perform RAPID-Net Guided Docking with AutoDock Vina üéØ** { display-mode: "form" }

import os
import time
import pandas as pd
from meeko import PDBQTMolecule, RDKitMolCreate
from rdkit import Chem
from rdkit.Chem import SDWriter

from meeko import MoleculePreparation, PDBQTMolecule, RDKitMolCreate
from rdkit.Chem import AddHs, MolFromMolFile, SDWriter
import subprocess

!rm -r /content/sample_data
!wget https://github.com/ccsb-scripps/AutoDock-Vina/releases/download/v1.2.7/vina_1.2.7_linux_x86_64 -O vina
!chmod u+x vina

# %alias vina /content/vina

cpu_cores = os.cpu_count()

Exhaustiveness = 32  # Ensure this is an integer
num_modes = 40

# **Restrict execution to only WRK_DIR**
subfolder_path = WRK_DIR  # Use WRK_DIR instead of looping through multiple subfolders

def extract_vina_scores(log_file, output_csv):
    with open(log_file, 'r') as file:
        lines = file.readlines()

    scores = []
    start_collecting = False
    for line in lines:
        if start_collecting:
            parts = line.split()
            if len(parts) == 4 and parts[0].isdigit():
                scores.append({
                    "NAME": f"{os.path.basename(log_file).split('_')[0]}_{parts[0]}",
                    "DOCK_SC": parts[1],
                    "RMSD_LB": parts[2],
                    "RMSD_UB": parts[3]
                })

        if "mode |   affinity | dist from best mode" in line:
            start_collecting = True

    df = pd.DataFrame(scores)
    df.to_csv(output_csv, index=False)
    print(f'+ {output_csv} > DOCKING folder')

# Ensure WRK_DIR exists before processing
if os.path.isdir(subfolder_path):
    for pocket_file in os.listdir(subfolder_path):
        if ("Minimal" in pocket_file or "Majority" in pocket_file) and pocket_file.endswith(".pdb"):
            pocket_name = os.path.splitext(pocket_file)[0]

            # Select the correct threshold list based on pocket type
            if "Minimal" in pocket_file:
                thresholds = minimal_thresholds
            elif "Majority" in pocket_file:
                thresholds = majority_thresholds
            else:
                continue  # Skip unknown pockets

            for threshold in thresholds:
                protein_file = prot_pdbqt_file_path
                ligand_file = lig_pdbqt_file_path

                config_file = os.path.join(subfolder_path, f"{pocket_name}_config_{threshold}.txt")
                docking_folder = os.path.join(subfolder_path, f"{pocket_name}_results_{threshold}")

                if not os.path.exists(protein_file) or not os.path.exists(ligand_file):
                    print(f"‚ùå Protein or ligand file missing in {WRK_DIR}. Skipping docking.")
                    continue

                ID = f"{os.path.basename(subfolder_path)}_{pocket_name}_{threshold}"
                oupt_log = f"{ID}_output.log"
                oupt_pdbqt = f"{ID}_output.pdbqt"
                oupt_log_dFFile = os.path.join(docking_folder, oupt_log)
                oupt_pdbqt_dFFile = os.path.join(docking_folder, oupt_pdbqt)

                print(f"üöÄ Starting docking for {ID}...")

                # -- Start docking --
                start_time = time.time()
#                 %vina --receptor {protein_file} --ligand {ligand_file} \
                --out {oupt_pdbqt_dFFile} --config {config_file} --cpu {cpu_cores} \
                --exhaustiveness {Exhaustiveness} --num_modes {num_modes} --verbosity 2 | tee {oupt_log_dFFile}
                end_time = time.time()  # Fix: Ensure end_time is set right after docking
                # -- End docking --

                print(f"‚úÖ Docking completed for {ID} in {end_time - start_time:.2f} seconds.")

                with open(oupt_pdbqt_dFFile, 'r') as oupt:
                    output_pdbqt = oupt.read()

                pdbqt_mol = PDBQTMolecule(output_pdbqt)
                rdkit_mol = RDKitMolCreate.from_pdbqt_mol(pdbqt_mol)[0]

                for conf_id in range(rdkit_mol.GetNumConformers()):
                    LIG_dash_sdf = f"{ID}_pose_{conf_id + 1}.sdf"
                    LIG_dash_sdf_dFFile = os.path.join(docking_folder, LIG_dash_sdf)
                    writer = SDWriter(str(LIG_dash_sdf_dFFile))
                    writer.write(rdkit_mol, confId=conf_id)
                    writer.close()

                extract_vina_scores(oupt_log_dFFile, os.path.join(docking_folder, f"{ID}_dockrpt.csv"))

else:
    print(f"‚ö†Ô∏è Working directory {WRK_DIR} does not exist. Skipping.")

# @title **üî¨ Select the Most Energetically Favorable Pose Based on Vina Scoring üìä** { display-mode: "form" }

import os
import pandas as pd
import shutil

base_dir = WRK_DIR

docking_scores = {}

def list_files_in_directory(directory, extension):
    file_paths = []
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.endswith(extension):
                file_paths.append(os.path.join(root, file))
    return file_paths

csv_files = list_files_in_directory(base_dir, "_dockrpt.csv")

print(f"All CSV files found in {base_dir} and subdirectories:")
for file in csv_files:
    print(file)

for file_path in csv_files:
    try:
        df = pd.read_csv(file_path)
        print(f"CSV Columns in {file_path}: {df.columns}")
        if 'DOCK_SC' in df.columns:
            scores = df['DOCK_SC'].astype(float).tolist()
            for score in scores:
                docking_scores[score] = file_path
            print(f"Found docking scores in {file_path}: {scores}")
        else:
            print(f"DOCK_SC column not found in {file_path}")
    except pd.errors.EmptyDataError:
        print(f"CSV file is empty: {file_path}")
    except pd.errors.ParserError:
        print(f"CSV file is malformed: {file_path}")
    except Exception as e:
        print(f"Error reading CSV file {file_path}: {e}")

print(f"Total number of docking scores found: {len(docking_scores)}")
print("Docking scores:", list(docking_scores.keys()))

# Find the most energetically favorable binding pose (i.e., the pose with the lowest docking score)
if docking_scores:
    most_favorable_score = min(docking_scores.keys())
    most_favorable_file = docking_scores[most_favorable_score]
    print(f"Most energetically favorable docking score: {most_favorable_score}")
    print(f"File containing the most energetically favorable pose: {most_favorable_file}")
    # Extract the folder path
    most_favorable_folder = os.path.dirname(most_favorable_file)
    print(f"Folder containing the most energetically favorable pose: {most_favorable_folder}")

    # Search for the file ending in '_pose_1.sdf' within the most favorable folder
    leading_pose_file = None
    for root, dirs, files in os.walk(most_favorable_folder):
        for file in files:
            if file.endswith("_pose_1.sdf"):
                leading_pose_file = os.path.join(root, file)
                break
        if leading_pose_file:
            break

    if leading_pose_file:
        print(f"Leading binding pose file found: {leading_pose_file}")
        # Extract the protein name from the base directory
        protein_name = os.path.basename(base_dir)
        new_file_name = f"{protein_name}_predicted_pose.sdf"
        predicted_pose_path = os.path.join(base_dir, new_file_name)

        # Copy the leading binding pose file to the base directory with the new name
        shutil.copy(leading_pose_file, predicted_pose_path)
        print(f"Leading binding pose file copied to: {predicted_pose_path}")
    else:
        print("No leading binding pose file found ending with '_pose_1.sdf'.")
else:
    print("No docking scores found.")

#@title ‚öñÔ∏è **Keep in mind: Reweighting Vina-predicted Poses Can Boost Accuracy** { display-mode: "form" }

# @markdown Top-1 Vina poses aren't always the best. Subleading poses can be better than Vina Top-1,
# @markdown so consider reweighting the ensemble with alternative methods to boost docking accuracy.

# @markdown See more details in https://arxiv.org/abs/2502.02371

import urllib.request
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

url = "https://raw.githubusercontent.com/BalytskyiJaroslaw/RAPID-Net/main/PoseBusters_Ensembled_Vina_VS_AlphaFold3.png"
with urllib.request.urlopen(url) as response:
    img = Image.open(response)

img = np.array(img)

plt.figure(figsize=(18, 10))
plt.imshow(img)
plt.axis('off')
plt.tight_layout()
plt.show()

# @title **Upload the List of True Poses üì•‚úîÔ∏è** { display-mode: "form" }
#@markdown Please upload the file with the true binding poses.

#@markdown In this case, it is **8F4J_PHO_ligands.sdf**.


import os
import shutil
from google.colab import files


# Upload true ligand pose files
print("\nüì§ Please upload the true ligand poses file (SDF format):")
uploaded = files.upload()  # Allows multiple files

# Store paths in a list
true_ligand_poses_path = []

# Move uploaded files to WRK_DIR and store their paths
for filename in uploaded.keys():
    src_path = os.path.join("/content", filename)  # Initial upload location
    dest_path = os.path.join(WRK_DIR, filename)  # Move to WRK_DIR
    shutil.move(src_path, dest_path)  # Move file
    true_ligand_poses_path.append(dest_path)  # Store path in list
    print(f"‚úÖ Moved {filename} to working directory: `{dest_path}`")

print("\n‚úÖ All true ligand pose files are now in the working directory.")
print(f"üìÇ True ligand poses saved at: {true_ligand_poses_path}")

"""# If the predicted pose passes the test with respect to <u><i>at least one</i></u> of the ground-truth poses, it's considered a win!"""

# @title üåü **Perfect Docking Run Example, passing both RMSD < 2 √Ö & All Chemical Validity Tests** üß™üß¨ { display-mode: "form" }

#@markdown ‚ùó‚ùó‚ùó **Note on Docking Variability:**
#@markdown Due an the **inherently stochastic nature** of docking, results may **slightly vary between runs**.

# @markdown For this protein, the predicted poses consistently have RMSD < 2 √Ö, but sometimes 1 or 2 of PB tests are failed.

print("Installing PoseBusters chemical validity tests...")
!pip install posebusters

import os
from rdkit import Chem
from rdkit.Chem import AllChem
import subprocess
import re

def calculate_rmsd(true_ligand, predicted_ligand_path):
    predicted_ligand = Chem.MolFromMolFile(predicted_ligand_path)
    if predicted_ligand is None:
        raise ValueError(f"Could not load predicted ligand from {predicted_ligand_path}")

    try:
        rmsd_value = AllChem.CalcRMS(true_ligand, predicted_ligand)
    except RuntimeError:
        raise RuntimeError("No sub-structure match found between the reference and probe mol")

    return rmsd_value

def is_pose_correct(rmsd_value, threshold=2.0):
    return rmsd_value <= threshold

# Define file paths in WRK_DIR
predicted_ligand_path = predicted_pose_path
protein_path = prot_pdb_rm_bad_path
true_ligands_path = true_ligand_poses_path[0]

# Validate that required files exist
if not os.path.exists(predicted_ligand_path) or not os.path.exists(protein_path) or not os.path.exists(true_ligands_path):
    print(f"‚ùå Missing required files in {WRK_DIR}. Please check the input files.")
    raise SystemExit

# Load true ligands
true_ligands_supplier = Chem.SDMolSupplier(true_ligands_path)
true_ligands = [ligand for ligand in true_ligands_supplier if ligand is not None]
num_true_poses = len(true_ligands)
print(f"Number of true binding poses in {WRK_DIR}: {num_true_poses}")

# Tracking pose passing status
pose_passed_rmsd_only = 0
pose_passed_both = 0

for i, true_ligand in enumerate(true_ligands):
    print(f"üîç Checking predicted binding pose vs true binding pose number {i+1}")

    try:
        rmsd_value = calculate_rmsd(true_ligand, predicted_ligand_path)
        print(f"üìè RMSD for {WRK_DIR} (true pose {i+1}): {rmsd_value}")

        if not is_pose_correct(rmsd_value):
            print(f"‚ùå Pose {i+1} failed RMSD < 2 √Ö.")
            continue

        print(f"‚úÖ Pose {i+1} passed RMSD < 2 √Ö.")

        command = [
            'bust',
            predicted_ligand_path,
            '-l', true_ligands_path,
            '-p', protein_path
        ]

        result = subprocess.run(command, capture_output=True, text=True, check=True)
        output = result.stdout
        print(output)

        match = re.search(r'passes \((\d+) / (\d+)\)', output)
        if match:
            passed_tests = int(match.group(1))
            total_tests = int(match.group(2))

            print(f"üß™ PoseBusters test result for {WRK_DIR} (true pose {i+1}): {passed_tests} / {total_tests}")

            if passed_tests == total_tests:
                pose_passed_both += 1
                print(f"‚úÖ Pose {i+1} passes both RMSD < 2 √Ö and all PoseBusters tests.")
            else:
                pose_passed_rmsd_only += 1
                print(f"‚ö†Ô∏è Pose {i+1} passes RMSD but failed PoseBusters tests.")
        else:
            print(f"‚ö†Ô∏è PoseBusters test did not pass for {WRK_DIR} (true pose {i+1}).")
            pose_passed_rmsd_only += 1

    except (ValueError, RuntimeError, subprocess.CalledProcessError) as e:
        print(f"‚ùå Error processing {WRK_DIR} (true pose {i+1}): {e}")

# Final Summary
print(f"\nüìä Final Summary for `{WRK_DIR}`:")
print(f"‚úÖ Poses passing both RMSD < 2 √Ö and all PoseBusters tests: {pose_passed_both}")
print(f"‚ö†Ô∏è Poses passing only RMSD < 2 √Ö but failing PoseBusters tests: {pose_passed_rmsd_only}")

# @title ‚úÖ **In this run, all tests successfully passed! üòä** { display-mode: "form" }

from IPython.display import display, HTML

display(HTML('''
<h3 style="color:green;">‚úÖ In this run, all tests successfully passed! üòä</h3>
<p style="color:gray;">If any tests had failed, don't worry‚Äîjust try your luck again! üçÄüòä</p>
'''))

# @title üî¨ **Now, perform RMSD & Chemical Validity Tests for the run we just did** üß™üß¨ { display-mode: "form" }

print("Installing PoseBusters chemical validity tests...")
!pip install posebusters

import os
from rdkit import Chem
from rdkit.Chem import AllChem
import subprocess
import re

def calculate_rmsd(true_ligand, predicted_ligand_path):
    predicted_ligand = Chem.MolFromMolFile(predicted_ligand_path)
    if predicted_ligand is None:
        raise ValueError(f"Could not load predicted ligand from {predicted_ligand_path}")

    try:
        rmsd_value = AllChem.CalcRMS(true_ligand, predicted_ligand)
    except RuntimeError:
        raise RuntimeError("No sub-structure match found between the reference and probe mol")

    return rmsd_value

def is_pose_correct(rmsd_value, threshold=2.0):
    return rmsd_value <= threshold

# Define file paths in WRK_DIR
predicted_ligand_path = predicted_pose_path
protein_path = prot_pdb_rm_bad_path
true_ligands_path = true_ligand_poses_path[0]

# Validate that required files exist
if not os.path.exists(predicted_ligand_path) or not os.path.exists(protein_path) or not os.path.exists(true_ligands_path):
    print(f"‚ùå Missing required files in {WRK_DIR}. Please check the input files.")
    raise SystemExit

# Load true ligands
true_ligands_supplier = Chem.SDMolSupplier(true_ligands_path)
true_ligands = [ligand for ligand in true_ligands_supplier if ligand is not None]
num_true_poses = len(true_ligands)
print(f"Number of true binding poses in {WRK_DIR}: {num_true_poses}")

# Tracking pose passing status
pose_passed_rmsd_only = 0
pose_passed_both = 0

for i, true_ligand in enumerate(true_ligands):
    print(f"üîç Checking predicted binding pose vs true binding pose number {i+1}")

    try:
        rmsd_value = calculate_rmsd(true_ligand, predicted_ligand_path)
        print(f"üìè RMSD for {WRK_DIR} (true pose {i+1}): {rmsd_value}")

        if not is_pose_correct(rmsd_value):
            print(f"‚ùå Pose {i+1} failed RMSD < 2 √Ö.")
            continue

        print(f"‚úÖ Pose {i+1} passed RMSD < 2 √Ö.")

        command = [
            'bust',
            predicted_ligand_path,
            '-l', true_ligands_path,
            '-p', protein_path
        ]

        result = subprocess.run(command, capture_output=True, text=True, check=True)
        output = result.stdout
        print(output)

        match = re.search(r'passes \((\d+) / (\d+)\)', output)
        if match:
            passed_tests = int(match.group(1))
            total_tests = int(match.group(2))

            print(f"üß™ PoseBusters test result for {WRK_DIR} (true pose {i+1}): {passed_tests} / {total_tests}")

            if passed_tests == total_tests:
                pose_passed_both += 1
                print(f"‚úÖ Pose {i+1} passes both RMSD < 2 √Ö and all PoseBusters tests.")
            else:
                pose_passed_rmsd_only += 1
                print(f"‚ö†Ô∏è Pose {i+1} passes RMSD but failed PoseBusters tests.")
        else:
            print(f"‚ö†Ô∏è PoseBusters test did not pass for {WRK_DIR} (true pose {i+1}).")
            pose_passed_rmsd_only += 1

    except (ValueError, RuntimeError, subprocess.CalledProcessError) as e:
        print(f"‚ùå Error processing {WRK_DIR} (true pose {i+1}): {e}")

# Final Summary
print(f"\nüìä Final Summary for `{WRK_DIR}`:")
print(f"‚úÖ Poses passing both RMSD < 2 √Ö and all PoseBusters tests: {pose_passed_both}")
print(f"‚ö†Ô∏è Poses passing only RMSD < 2 √Ö but failing PoseBusters tests: {pose_passed_rmsd_only}")

# @title **üñºÔ∏èüé®üîç Your protein with Majority-voted pockets & true binding poses** { display-mode: "form" }

import py3Dmol
from rdkit import Chem
import numpy as np
import os
from Bio.PDB import PDBParser

# Get user input for residues (comma-separated)
residues_input = ""  # @param {type:"string"}
residues_to_highlight = [int(res.strip()) for res in residues_input.split(",") if res.strip().isdigit()]
highlight_color = "red"

# Locate pocket files
cyan_pocket_paths = [
    os.path.join(WRK_DIR, file) for file in os.listdir(WRK_DIR)
    if file.startswith("pocket") and "Majority" in file and file.endswith(".pdb")
]

# Functions to compute geometric centers
def compute_residue_center(residue):
    atom_coords = [atom.coord for atom in residue if atom.element != 'H']
    if atom_coords:
        return np.mean(atom_coords, axis=0)
    return None

def compute_pocket_center(pocket_path):
    parser = PDBParser(QUIET=True)
    structure = parser.get_structure("pocket", pocket_path)
    coords = []
    for model in structure:
        for chain in model:
            for residue in chain:
                for atom in residue:
                    if atom.element != 'H':
                        coords.append(atom.coord)
    if coords:
        return np.mean(coords, axis=0)
    return None

# Parse main protein
parser = PDBParser(QUIET=True)
structure = parser.get_structure("protein", protein_file)

# Calculate residue centers
residue_centers = {}
for model in structure:
    for chain in model:
        for residue in chain:
            res_id = residue.id[1]
            chain_id = chain.id
            center = compute_residue_center(residue)
            if center is not None:
                residue_centers[(chain_id, res_id)] = center

# Initialize 3D viewer
viewer = py3Dmol.view(width=1500, height=900)

# Load protein structure
with open(protein_file, 'r') as protein_data:
    viewer.addModel(protein_data.read(), 'pdb')
viewer.setStyle({'model': 0}, {"cartoon": {"color": "spectrum"}})

model_index = 1

# Load cyan-colored pockets
for pocket_path in cyan_pocket_paths:
    with open(pocket_path, 'r') as pocket_data:
        viewer.addModel(pocket_data.read(), 'pdb')
    viewer.setStyle(
        {'model': model_index},
        {'stick': {'color': 'cyan', 'radius': 0.1, 'opacity': 0.8}}
    )
    # Label pocket center
    pocket_center = compute_pocket_center(pocket_path)
    if pocket_center is not None:
        x, y, z = map(float, pocket_center)
        pocket_name = os.path.splitext(os.path.basename(pocket_path))[0]
        viewer.addLabel(
            pocket_name,
            {
                "position": {"x": x, "y": y, "z": z},
                "fontColor": "black",
                "font": "Helvetica",
                "fontSize": 14,
                "backgroundColor": "white",
                "showBackground": True,
                "opacity": 1.0,
                "inFront": True,
                "screenOffset": {"x": 10, "y": -10}
            }
        )
    model_index += 1

# Highlight selected residues
for (chain_id, res_id), center in residue_centers.items():
    if res_id in residues_to_highlight:
        viewer.addStyle(
            {"chain": chain_id, "resi": res_id},
            {"stick": {"color": highlight_color, "radius": 0.3}}
        )
        res_name = structure[0][chain_id][(' ', res_id, ' ')].resname
        label = f"{res_name}{res_id}"
        x, y, z = map(float, center)
        viewer.addLabel(label, {
            "position": {"x": x, "y": y, "z": z},
            "fontColor": highlight_color,
            "font": "Helvetica",
            "fontSize": 14,
            "backgroundColor": "black",
            "showBackground": True,
            "opacity": 1.0,
            "inFront": True,
            "screenOffset": {"x": 5, "y": -5}
        })

# ---------------------------------------
# Load true ligand poses (red sticks)
# ---------------------------------------
# If you have multiple SDFs in true_ligand_poses_path, loop over them.
# Below shows a single SDF as an example:
if true_ligand_poses_path:
    ligand_supplier = Chem.SDMolSupplier(true_ligand_poses_path[0])
    for ligand in ligand_supplier:
        if ligand is not None:
            ligand_block = Chem.MolToMolBlock(ligand)
            viewer.addModel(ligand_block, 'mol')
            viewer.setStyle({'model': model_index}, {"stick": {"colorscheme": "redCarbon"}})
            model_index += 1

# -------------------------------------------------
# Load the predicted binding pose (green stick+sphere)
# -------------------------------------------------
predicted_pose = Chem.MolFromMolFile(predicted_ligand_path)
if predicted_pose is not None:
    predicted_pose_block = Chem.MolToMolBlock(predicted_pose)
    viewer.addModel(predicted_pose_block, 'mol')
    viewer.setStyle(
        {'model': model_index},
        {
            "stick": {"colorscheme": "greenCarbon"},
            "sphere": {"scale": 0.3}
        }
    )
    model_index += 1

viewer.zoomTo()
viewer.show()

# @title **üñºÔ∏èüé®üîç Only Pockets & Ligands shown, no protein** { display-mode: "form" }

# @markdown **Possible true ligand binding poses are shown in red, predicted one is shown in green.**
import py3Dmol
from rdkit import Chem
import numpy as np
import os
from Bio.PDB import PDBParser

# --------------------------------------------------------------------
# No protein is loaded here. Only pockets & ligands will be displayed.
# --------------------------------------------------------------------

# Function to compute the geometric center of an entire pocket
def compute_pocket_center(pocket_path):
    parser = PDBParser(QUIET=True)
    structure = parser.get_structure("pocket", pocket_path)
    coords = []
    for model in structure:
        for chain in model:
            for residue in chain:
                for atom in residue:
                    if atom.element != 'H':
                        coords.append(atom.coord)
    if coords:
        return np.mean(coords, axis=0)
    return None

# Locate majority-voted pocket files
cyan_pocket_paths = [
    os.path.join(WRK_DIR, file) for file in os.listdir(WRK_DIR)
    if file.startswith("pocket") and "Majority" in file and file.endswith(".pdb")
]

# Initialize 3D viewer
viewer = py3Dmol.view(width=1200, height=900)

model_index = 0

# Load cyan-colored pockets
for pocket_path in cyan_pocket_paths:
    with open(pocket_path, 'r') as pocket_data:
        viewer.addModel(pocket_data.read(), 'pdb')
    viewer.setStyle(
        {'model': model_index},
        {'stick': {'color': 'cyan', 'radius': 0.1, 'opacity': 0.8}}
    )
    # Label pocket center
    pocket_center = compute_pocket_center(pocket_path)
    if pocket_center is not None:
        x, y, z = map(float, pocket_center)
        pocket_name = os.path.splitext(os.path.basename(pocket_path))[0]
        viewer.addLabel(
            pocket_name,
            {
                "position": {"x": x, "y": y, "z": z},
                "fontColor": "black",
                "font": "Helvetica",
                "fontSize": 14,
                "backgroundColor": "white",
                "showBackground": True,
                "opacity": 1.0,
                "inFront": True,
                "screenOffset": {"x": 10, "y": -10}
            }
        )
    model_index += 1

# ---------------------------------------
# Load true ligand poses (red sticks)
# ---------------------------------------
if true_ligand_poses_path:
    ligand_supplier = Chem.SDMolSupplier(true_ligand_poses_path[0])
    for ligand in ligand_supplier:
        if ligand is not None:
            ligand_block = Chem.MolToMolBlock(ligand)
            viewer.addModel(ligand_block, 'mol')
            viewer.setStyle({'model': model_index}, {"stick": {"colorscheme": "redCarbon"}})
            model_index += 1

# -------------------------------------------------
# Load the predicted binding pose (green stick+sphere)
# -------------------------------------------------
predicted_pose = Chem.MolFromMolFile(predicted_ligand_path)
if predicted_pose is not None:
    predicted_pose_block = Chem.MolToMolBlock(predicted_pose)
    viewer.addModel(predicted_pose_block, 'mol')
    viewer.setStyle(
        {'model': model_index},
        {
            "stick": {"colorscheme": "greenCarbon"},
            "sphere": {"scale": 0.3}
        }
    )
    model_index += 1

viewer.zoomTo()
viewer.show()

#@title **Download PUResNet V2 predictions for 8F4J, to compare against RAPID-Net** { display-mode: "form" }

!pip install wget

import wget
import os
import zipfile

url = 'https://zenodo.org/records/15001676/files/8F4J_PHO_protein_PUResNet_V2_prediction.zip'
zip_path = '/content/8F4J_PHO_protein_PUResNet_V2_prediction.zip'
extract_dir = '/content/8F4J_PHO_protein_PUResNet_V2_prediction'


print("Downloading ZIP file...")
wget.download(url, zip_path)

os.makedirs(extract_dir, exist_ok=True)
print("\nUnzipping the file...")
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_dir)

print(f"‚úÖ Unzipping complete! Files extracted to: {extract_dir}")

#@title **For comparison, ''Majority-voted'' pocket predicted by RAPID-Net VS PUResNet V2 predictions** { display-mode: "form" }
#@markdown **One can see that RAPID-Net gives a more straightforward and plug-and-play input for docking**


import glob
import py3Dmol
from rdkit import Chem

ligands_path = "/content/gdrive/MyDrive/Docking_benchmarks/Interesting_Cases/Extreme_cases/8F4J_PHO/8F4J_PHO/8F4J_PHO_ligands.sdf"
predicted_pose_path = "/content/gdrive/MyDrive/Docking_benchmarks/Interesting_Cases/Extreme_cases/8F4J_PHO/8F4J_PHO/8F4J_PHO_predicted_pose.sdf"

pocket_paths = [
    os.path.join(WRK_DIR, file) for file in os.listdir(WRK_DIR)
    if file.startswith("pocket") and "Majority" in file and file.endswith(".pdb")
]

PUResNet_V2_directory = '/content/8F4J_PHO_protein_PUResNet_V2_prediction/8F4J_PHO_protein'


interacting_residues_paths = [f for f in os.listdir(PUResNet_V2_directory) if os.path.isfile(os.path.join(PUResNet_V2_directory, f))]
viewer = py3Dmol.view(width=1000, height=800)




interacting_residues_paths = glob.glob(f'{PUResNet_V2_directory}/**/*', recursive=True)

model_index = 0

# Load true ligand poses (in red, stick style)
ligand_supplier = Chem.SDMolSupplier(true_ligands_path)
for ligand in ligand_supplier:
    if ligand is not None:
        ligand_block = Chem.MolToMolBlock(ligand)
        viewer.addModel(ligand_block, 'mol')
        viewer.setStyle({'model': model_index}, {"stick": {"colorscheme": "redCarbon"}})
        model_index += 1

# Load predicted pose (in green, ball-and-stick style)
predicted_pose = Chem.SDMolSupplier(predicted_ligand_path)[0]
if predicted_pose is not None:
    predicted_pose_block = Chem.MolToMolBlock(predicted_pose)
    viewer.addModel(predicted_pose_block, 'mol')
    viewer.setStyle({'model': model_index}, {
        "stick": {"colorscheme": "greenCarbon"},
        "sphere": {"scale": 0.3}
    })
    model_index += 1

# Load pockets (as sticks with cyan color, 0.3 radius, and 0.7 opacity)
for pocket_path in pocket_paths:
    with open(pocket_path, 'r') as pocket_file:
        pocket_data = pocket_file.read()
    viewer.addModel(pocket_data, 'pdb')
    viewer.setStyle({'model': model_index}, {
        'stick': {'color': 'cyan', 'radius': 0.1, 'opacity': 0.7}
    })
    model_index += 1

# Load interacting residues (as sticks with yellow color, 0.3 radius)
for residue_path in interacting_residues_paths:
    with open(residue_path, 'r') as residue_file:
        residue_data = residue_file.read()
    viewer.addModel(residue_data, 'pdb')
    viewer.setStyle({'model': model_index}, {
        'stick': {
            'color': 'yellow',
            'radius': 0.3
        }
    })
    model_index += 1

# Finalize viewer
viewer.zoomTo()
viewer.show()

#@title **For comparison, if you rerun the pocket predictor, here are the ''Minority-reported'' pockets with a lower theshold = 0.30** { display-mode: "form" }
#@markdown **One can see 3 out of 4 poses covered, one partially**

import py3Dmol
from rdkit import Chem
import numpy as np
import os
from Bio.PDB import PDBParser

predicted_ligand_path = '/content/8F4J/8F4J_PHO_predicted_pose.sdf'

# --------------------------------------------------------------------
# No protein is loaded here. Only pockets & ligands will be displayed.
# --------------------------------------------------------------------

# Function to compute the geometric center of an entire pocket
def compute_pocket_center(pocket_path):
    parser = PDBParser(QUIET=True)
    structure = parser.get_structure("pocket", pocket_path)
    coords = []
    for model in structure:
        for chain in model:
            for residue in chain:
                for atom in residue:
                    if atom.element != 'H':
                        coords.append(atom.coord)
    if coords:
        return np.mean(coords, axis=0)
    return None

# Locate majority-voted pocket files
cyan_pocket_paths = [
    os.path.join(WRK_DIR, file) for file in os.listdir(WRK_DIR)
    if file.startswith("pocket") and "Minimal" in file and file.endswith(".pdb")
]

# Initialize 3D viewer
viewer = py3Dmol.view(width=1200, height=900)

model_index = 0

# Load cyan-colored pockets
for pocket_path in cyan_pocket_paths:
    with open(pocket_path, 'r') as pocket_data:
        viewer.addModel(pocket_data.read(), 'pdb')
    viewer.setStyle(
        {'model': model_index},
        {'stick': {'color': 'purple', 'radius': 0.3, 'opacity': 0.8}}
    )
    # Label pocket center
    pocket_center = compute_pocket_center(pocket_path)
    if pocket_center is not None:
        x, y, z = map(float, pocket_center)
        pocket_name = os.path.splitext(os.path.basename(pocket_path))[0]
        viewer.addLabel(
            pocket_name,
            {
                "position": {"x": x, "y": y, "z": z},
                "fontColor": "black",
                "font": "Helvetica",
                "fontSize": 14,
                "backgroundColor": "white",
                "showBackground": True,
                "opacity": 1.0,
                "inFront": True,
                "screenOffset": {"x": 10, "y": -10}
            }
        )
    model_index += 1

# ---------------------------------------
# Load true ligand poses (red sticks)
# ---------------------------------------
if true_ligand_poses_path:
    ligand_supplier = Chem.SDMolSupplier(true_ligand_poses_path[0])
    for ligand in ligand_supplier:
        if ligand is not None:
            ligand_block = Chem.MolToMolBlock(ligand)
            viewer.addModel(ligand_block, 'mol')
            viewer.setStyle({'model': model_index}, {"stick": {"colorscheme": "redCarbon"}})
            model_index += 1

# -------------------------------------------------
# Load the predicted binding pose (green stick+sphere)
# -------------------------------------------------
predicted_pose = Chem.MolFromMolFile(predicted_ligand_path)
if predicted_pose is not None:
    predicted_pose_block = Chem.MolToMolBlock(predicted_pose)
    viewer.addModel(predicted_pose_block, 'mol')
    viewer.setStyle(
        {'model': model_index},
        {
            "stick": {"colorscheme": "greenCarbon"},
            "sphere": {"scale": 0.3}
        }
    )
    model_index += 1

viewer.zoomTo()
viewer.show()

# Commented out IPython magic to ensure Python compatibility.
# @title **Make FPocket prediction, for comparison** { display-mode: "form" }

import os
import subprocess

print("Intalling FPocket...")
!apt-get update
!apt-get install -y git make gcc g++

!git clone https://github.com/Discngine/fpocket.git

# %cd fpocket
!make
!sudo make install

!fpocket -h

print("FPocket installed!")

WRK_DIR_fp = "/content"
fpocket_subfolder = os.path.join(WRK_DIR_fp, "fpocket")
os.makedirs(fpocket_subfolder, exist_ok=True)

# Move into the fpocket_subfolder
# %cd $fpocket_subfolder

print("Predicting pockets by FPocket...")
# 6) Run Fpocket on your protein:
fpocket_command = f"fpocket -f {protein_file}"
subprocess.run(fpocket_command, shell=True)

print("FPocket prediction complete!")

# @title üîç **FPocket Prediction for This Protein** üß¨ { display-mode: "form" }

#@markdown ---
#@markdown üß™ **FPocket:**
#@markdown The **alpha-spheres** predicted by FPocket cover the **entire protein**, drastically increasing the **search space** üî≠.

#@markdown As a result, even powerful docking tools like **AlphaFold 3** struggle to process the protein as a whole ‚öôÔ∏è.

#@markdown üöÄ **RAPID-Net Advantage:**
#@markdown In contrast, **RAPID-Net guided docking** using **AutoDock Vina** succeeds with **minimal computational cost**, offering an cost-efficient solution.

import py3Dmol
import os

# Automatically find the directory with FPocket predictions.
pockets_dir = None
for subdir in os.listdir(WRK_DIR):
    if subdir.endswith('_out'):
        potential_pockets_dir = os.path.join(WRK_DIR, subdir, 'pockets')
        if os.path.isdir(potential_pockets_dir):
            pockets_dir = potential_pockets_dir
            break

if pockets_dir is None:
    raise FileNotFoundError("No pockets directory found in '_out' subdirectory.")

protein_path = protein_file

view = py3Dmol.view(width=800, height=600)

with open(protein_path, 'r') as f:
    protein_data = f.read()
view.addModel(protein_data, 'pdb')

# Load and add pocket models
model_index = 1
for filename in os.listdir(pockets_dir):
    if filename.endswith('_atm.pdb'):
        pocket_path = os.path.join(pockets_dir, filename)
        with open(pocket_path, 'r') as f:
            pocket_data = f.read()
        view.addModel(pocket_data, 'pdb')
        view.setStyle({'model': model_index}, {'stick': {'color': 'green'}})
        model_index += 1

# Load and add all alpha sphere files
for filename in os.listdir(pockets_dir):
    if filename.endswith('_vert.pqr'):
        alpha_sphere_path = os.path.join(pockets_dir, filename)
        with open(alpha_sphere_path, 'r') as f:
            alpha_sphere_data = f.read()
        # Extract coordinates and radii from PQR data
        for line in alpha_sphere_data.splitlines():
            if line.startswith('ATOM'):
                parts = line.split()
                x = float(parts[5])
                y = float(parts[6])
                z = float(parts[7])
                radius = float(parts[9])
                view.addSphere({'center': {'x': x, 'y': y, 'z': z}, 'radius': radius, 'color': 'magenta', 'alpha': 0.6})

view.setStyle({'model': 0}, {'cartoon': {'color': 'spectrum'}})
view.zoomTo()
view.show()

# @title üìö **Reference to AlphaFold 3 (AF3):** { display-mode: "form" }

# @markdown Abramson, J., Adler, J., Dunger, J. *et al.* (2024). "Accurate structure prediction of biomolecular interactions with AlphaFold 3".
# @markdown *Nature*, 617, 583‚Äì589. [DOI: 10.1038/s41586-024-07487-w](https://doi.org/10.1038/s41586-024-07487-w)

import urllib.request
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

# ‚úÖ Use the raw image link
url = "https://github.com/BalytskyiJaroslaw/RAPID-Net/raw/main/Comparison/Reference_from_AF3.png"

with urllib.request.urlopen(url) as response:
    img = Image.open(response)

img = np.array(img)

plt.figure(figsize=(18, 10))
plt.imshow(img)
plt.axis('off')
plt.tight_layout()
plt.show()

# @title üìö **Reference to Uni-Mol:** { display-mode: "form" }

# @markdown Zhou, G., Gao, Z., Ding, Q., Zheng, H., Xu, H., Wei, Z., Zhang, L., & Ke, G. (2023). *Uni-Mol: A Universal 3D Molecular Representation Learning Framework*. ChemRxiv. [https://doi.org/10.26434/chemrxiv-2022-jjm0j](https://doi.org/10.26434/chemrxiv-2022-jjm0j)

import urllib.request
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

# ‚úÖ Use the raw image link from GitHub
url = "https://github.com/BalytskyiJaroslaw/RAPID-Net/raw/main/Comparison/FPocket.png"

with urllib.request.urlopen(url) as response:
    img = Image.open(response)

img = np.array(img)

plt.figure(figsize=(18, 10))
plt.imshow(img)
plt.axis('off')
plt.tight_layout()
plt.show()

from google.colab import drive
drive.mount('/content/drive')

# @title üíæ **(Optional): zip and save the output** { display-mode: "form" }

# @markdown Provide the folder path where the results (the `.zip` file) should be saved.

folder_path_to_save = "/content/drive/MyDrive/8F4J"  #@param {type:"string"}

import os
import shutil

wrkdir_basename = os.path.basename(WRK_DIR.strip('/'))
zip_filename = wrkdir_basename + ".zip"
zip_filepath = os.path.join(folder_path_to_save, zip_filename)

print(f"Zipping the entire WRK_DIR: {WRK_DIR}")
shutil.make_archive(
    base_name=os.path.splitext(zip_filepath)[0],  # omit .zip extension for make_archive
    format='zip',
    root_dir=WRK_DIR
)
print(f"‚úÖ Zip archive created: {zip_filepath}")

